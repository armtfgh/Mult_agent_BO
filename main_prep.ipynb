{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8bc3b610",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amirreza/anaconda3/envs/pol_env/lib/python3.11/site-packages/torch/__init__.py:1264: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:434.)\n",
      "  _C._set_default_tensor_type(t)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Tiny, modular BoTorch BO for the nanoparticle oracle — CUDA version.\n",
    "\n",
    "Structure (as requested):\n",
    "- oracle_noisy(X, sigma): one function that returns *noisy* observations (GPU)\n",
    "- make_gp(train_x, train_y): one function that builds & fits the GP surrogate (GPU)\n",
    "- propose_candidates(model, train_x, use_qnehvi=True, q=1): one function for the AF (GPU)\n",
    "- run_bo(...): loop that alternates GP + AF for a number of iterations\n",
    "- visualize(...): plot best-so-far (Pareto) and hypervolume\n",
    "- visual_plus(...): per-iteration surrogate switching (policy-driven)\n",
    "- visual_plus_compare(...): compare multiple policies (e.g., Random vs Hybrid)\n",
    "\n",
    "Notes\n",
    "- We model **maximization** by using Y = 1 - normalize([size, PDI]) in [0,1]^2.\n",
    "  (So larger is better; ref_point = (0, 0).) Noise is added on the normalized scale.\n",
    "- qNEHVI is the robust default for noisy observations. qEHVI also provided.\n",
    "- Replace oracle_noisy(...) with your synthesizer if desired; keep its contract.\n",
    "\n",
    "Install: pip install botorch gpytorch torch matplotlib\n",
    "Run on GPU: ensure CUDA is available (torch.cuda.is_available()).\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "\n",
    "from botorch.models import SingleTaskGP, ModelListGP\n",
    "from botorch.fit import fit_gpytorch_mll\n",
    "from gpytorch.mlls import SumMarginalLogLikelihood\n",
    "\n",
    "from botorch.utils.transforms import normalize, unnormalize\n",
    "from botorch.utils.sampling import draw_sobol_samples\n",
    "from botorch.optim.optimize import optimize_acqf\n",
    "from botorch.sampling.normal import SobolQMCNormalSampler\n",
    "\n",
    "from botorch.acquisition.multi_objective.monte_carlo import (\n",
    "    qExpectedHypervolumeImprovement,\n",
    "    qNoisyExpectedHypervolumeImprovement,\n",
    ")\n",
    "from botorch.acquisition.multi_objective.logei import qLogNoisyExpectedHypervolumeImprovement\n",
    "from botorch.utils.multi_objective.box_decompositions.non_dominated import (\n",
    "    FastNondominatedPartitioning,\n",
    ")\n",
    "from botorch.utils.multi_objective.pareto import is_non_dominated\n",
    "from botorch.utils.multi_objective.hypervolume import Hypervolume\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ---------------------\n",
    "# CUDA setup\n",
    "# ---------------------\n",
    "if not torch.cuda.is_available():\n",
    "    raise RuntimeError(\"CUDA is not available. Please install a CUDA-enabled PyTorch or switch to the CPU version.\")\n",
    "\n",
    "DEVICE = torch.device(\"cuda\")\n",
    "DTYPE = torch.double\n",
    "\n",
    "# Make new tensors default to CUDA double unless otherwise specified\n",
    "torch.set_default_tensor_type(torch.cuda.DoubleTensor)\n",
    "\n",
    "# ---------------------\n",
    "# Globals & defaults\n",
    "# ---------------------\n",
    "DIM = 4\n",
    "bounds = torch.zeros(2, DIM, dtype=DTYPE, device=DEVICE)\n",
    "bounds[1] = 1  # standard [0,1]^4 design space\n",
    "REF_POINT = torch.tensor([0.0, 0.0], dtype=DTYPE, device=DEVICE)  # maximization\n",
    "\n",
    "BATCH_Q = 1\n",
    "NUM_RESTARTS = 10\n",
    "RAW_SAMPLES = 256\n",
    "MC_SAMPLES = 128\n",
    "\n",
    "# --------------------------------------\n",
    "# 1) Oracle with NOISY output (GPU-only)\n",
    "# --------------------------------------\n",
    "\n",
    "def _nanoparticle_oracle_torch(X: Tensor) -> Tensor:\n",
    "    \"\"\"Torch oracle on GPU: X (N,4) -> raw Y (N,2) [size, PDI] on DEVICE.\"\"\"\n",
    "    x1, x2, x3, x4 = X.unbind(dim=-1)\n",
    "    y1 = (\n",
    "        19.36549\n",
    "        - 0.2797 * x1\n",
    "        + 1.56885 * x2\n",
    "        + 3.5447 * x3\n",
    "        + 1.82225 * x4\n",
    "        - 1.1978 * x1 * x2\n",
    "        - 1.66594 * x1 * x3\n",
    "        - 1.62873 * x1 * x4\n",
    "        - 0.02003 * x2 * x3\n",
    "        - 0.001268 * x2 * x4\n",
    "        - 0.35086 * x3 * x4\n",
    "        + 0.3914 * (x1 ** 2)\n",
    "        + 0.52265 * (x2 ** 2)\n",
    "        - 0.81701 * (x3 ** 2)\n",
    "        - 2.74921 * (x4 ** 2)\n",
    "    )\n",
    "    y2 = (\n",
    "        19.6114239\n",
    "        + 1.0313718 * x1\n",
    "        + 1.48527 * x2\n",
    "        + 1.7991534 * x3\n",
    "        - 4.1983899 * x4\n",
    "        + 1.4263262 * x1 * x2\n",
    "        - 0.4279443 * x1 * x3\n",
    "        - 1.3865203 * x1 * x4\n",
    "        - 1.051601 * x2 * x3\n",
    "        - 2.06380 * x2 * x4\n",
    "        - 2.476674 * x3 * x4\n",
    "        - 0.4497319 * (x1 ** 2)\n",
    "        - 1.8040123 * (x2 ** 2)\n",
    "        - 3.8699325 * (x3 ** 2)\n",
    "        - 2.6148 * (x4 ** 2)\n",
    "    )\n",
    "    return torch.stack([y1, y2], dim=-1)\n",
    "\n",
    "# Pre-compute y-min/y-max for normalization via domain sampling (GPU)\n",
    "with torch.random.fork_rng(devices=[0]):\n",
    "    torch.manual_seed(0)\n",
    "    _Xs = torch.rand(30000, DIM, dtype=DTYPE, device=DEVICE)\n",
    "    _Ys = _nanoparticle_oracle_torch(_Xs)\n",
    "Y_MIN = _Ys.min(dim=0).values\n",
    "Y_MAX = _Ys.max(dim=0).values\n",
    "\n",
    "\n",
    "def oracle_noisy(X: Tensor, sigma: float = 0.05, seed: int | None = None) -> Tensor:\n",
    "    \"\"\"Return **noisy, normalized, maximization** outcomes Y in [0,1]^2 (GPU).\n",
    "\n",
    "    Contract (keep this if you swap with your synthesizer):\n",
    "      - Input: X (N, 4) in [0,1]^4 (unnormalized design space)\n",
    "      - Output: Y (N, 2) where larger is better (i.e., Y = 1 - norm([size, PDI]))\n",
    "      - Noise: Gaussian N(0, sigma^2) on the normalized scale, clipped to [0,1]\n",
    "    \"\"\"\n",
    "    X = X.to(device=DEVICE, dtype=DTYPE)\n",
    "    Y_raw = _nanoparticle_oracle_torch(X)  # (N,2) on GPU\n",
    "    Yn = (Y_raw - Y_MIN) / (Y_MAX - Y_MIN)\n",
    "    if seed is not None:\n",
    "        torch.manual_seed(int(seed))\n",
    "        torch.cuda.manual_seed_all(int(seed))\n",
    "    Yn = (Yn + sigma * torch.randn_like(Yn))\n",
    "    Yn = Yn.clamp(0.0, 1.0)\n",
    "    return 1.0 - Yn  # maximization\n",
    "\n",
    "\n",
    "# ---------------------------------\n",
    "# 2) Gaussian Process (single fn)\n",
    "# ---------------------------------\n",
    "\n",
    "def make_gp(train_x, train_y, state_dict=None, preset = \"m52_ard\"):\n",
    "    from surrogates import Surrogate, PRESETS\n",
    "    sg = Surrogate(PRESETS[preset])\n",
    "    Xn = normalize(train_x, bounds)\n",
    "    if state_dict is not None and sg.model is not None:\n",
    "        sg.model.load_state_dict(state_dict)\n",
    "    model, _ = sg.build(Xn, train_y, state_dict=(sg.model.state_dict() if sg.model else None))\n",
    "    return sg.model, None  # mll is stored in sg.mll\n",
    "\n",
    "\n",
    "# ---------------------------------\n",
    "# 3) Acquisition (single fn)\n",
    "# ---------------------------------\n",
    "\n",
    "def propose_candidates(\n",
    "    model,\n",
    "    train_x: Tensor,\n",
    "    use_qnehvi: bool = True,\n",
    "    q: int = BATCH_Q,\n",
    "):\n",
    "    \"\"\"Create the acquisition and return the next q candidates (unnormalized).\n",
    "    - qNEHVI for noisy observations (default). qEHVI optional.\n",
    "    - Optimizes over the standard [0,1]^4 bounds. (All CUDA tensors.)\n",
    "    \"\"\"\n",
    "    sampler = SobolQMCNormalSampler(sample_shape=torch.Size([MC_SAMPLES]))\n",
    "\n",
    "    if use_qnehvi:\n",
    "        acq = qLogNoisyExpectedHypervolumeImprovement(\n",
    "            model=model,\n",
    "            ref_point=REF_POINT,\n",
    "            X_baseline=normalize(train_x, bounds),\n",
    "            prune_baseline=True,\n",
    "            sampler=sampler,\n",
    "            cache_root=True,\n",
    "        )\n",
    "    else:\n",
    "        with torch.no_grad():\n",
    "            post_mean = model.posterior(normalize(train_x, bounds)).mean\n",
    "        part = FastNondominatedPartitioning(ref_point=REF_POINT, Y=post_mean)\n",
    "        acq = qExpectedHypervolumeImprovement(\n",
    "            model=model,\n",
    "            ref_point=REF_POINT,\n",
    "            partitioning=part,\n",
    "            sampler=sampler,\n",
    "        )\n",
    "\n",
    "    cand, _ = optimize_acqf(\n",
    "        acq_function=acq,\n",
    "        bounds=bounds,\n",
    "        q=q,\n",
    "        num_restarts=NUM_RESTARTS,\n",
    "        raw_samples=RAW_SAMPLES,\n",
    "        options={\"batch_limit\": 5, \"maxiter\": 200},\n",
    "        sequential=True,\n",
    "    )\n",
    "    return unnormalize(cand.detach(), bounds=bounds)\n",
    "\n",
    "\n",
    "# ---------------------------------\n",
    "# 4) BO loop (single fn)\n",
    "# ---------------------------------\n",
    "\n",
    "def run_bo(\n",
    "    n_init: int = 8,\n",
    "    n_iter: int = 20,\n",
    "    sigma: float = 0.05,\n",
    "    seed: int = 0,\n",
    "    use_qnehvi: bool = True,\n",
    "    preset = \"m52_ard\"\n",
    "):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "    # Initial design via Sobol on standard bounds (on GPU)\n",
    "    X_init = draw_sobol_samples(bounds=bounds, n=1, q=n_init, seed=seed).squeeze(0)\n",
    "    X_init = unnormalize(X_init, bounds=bounds)  # identity here; keeps API clear\n",
    "    Y_init = oracle_noisy(X_init, sigma=sigma, seed=seed)\n",
    "\n",
    "    model, mll = make_gp(X_init, Y_init,preset = preset )\n",
    "\n",
    "    train_x, train_y = X_init, Y_init\n",
    "    hv_vals = []\n",
    "\n",
    "    def compute_hv(Y: Tensor):\n",
    "        mask = is_non_dominated(Y)\n",
    "        hv = Hypervolume(ref_point=REF_POINT)\n",
    "        return float(hv.compute(Y[mask]))\n",
    "\n",
    "    hv_vals.append(compute_hv(train_y))\n",
    "\n",
    "    for _ in range(n_iter):\n",
    "        X_new = propose_candidates(model, train_x, use_qnehvi=use_qnehvi, q=BATCH_Q)\n",
    "        Y_new = oracle_noisy(X_new, sigma=sigma)\n",
    "        train_x = torch.cat([train_x, X_new])\n",
    "        train_y = torch.cat([train_y, Y_new])\n",
    "\n",
    "        state = model.state_dict()\n",
    "        model, mll = make_gp(train_x, train_y, state_dict=state, preset = preset )\n",
    "        hv_vals.append(compute_hv(train_y))\n",
    "\n",
    "    return train_x, train_y, torch.tensor(hv_vals, device=DEVICE, dtype=DTYPE)\n",
    "\n",
    "\n",
    "# ---------------------------------\n",
    "# 5) Random policy loop (single fn)\n",
    "# ---------------------------------\n",
    "\n",
    "def run_random(\n",
    "    n_init: int = 8,\n",
    "    n_iter: int = 20,\n",
    "    sigma: float = 0.05,\n",
    "    seed: int = 0,\n",
    "):\n",
    "    \"\"\"Baseline that ignores the model and selects points uniformly at random.\n",
    "    Returns the same tuple as run_bo: (X, Y, HV).\n",
    "    \"\"\"\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "    # Initial random design in [0,1]^4 on GPU\n",
    "    X_init = torch.rand(n_init, DIM, dtype=DTYPE, device=DEVICE)\n",
    "    Y_init = oracle_noisy(X_init, sigma=sigma, seed=seed)\n",
    "\n",
    "    train_x, train_y = X_init, Y_init\n",
    "    hv_vals = []\n",
    "\n",
    "    def compute_hv(Y: Tensor):\n",
    "        mask = is_non_dominated(Y)\n",
    "        hv = Hypervolume(ref_point=REF_POINT)\n",
    "        return float(hv.compute(Y[mask]))\n",
    "\n",
    "    hv_vals.append(compute_hv(train_y))\n",
    "\n",
    "    for _ in range(n_iter):\n",
    "        X_new = torch.rand(BATCH_Q, DIM, dtype=DTYPE, device=DEVICE)\n",
    "        Y_new = oracle_noisy(X_new, sigma=sigma)\n",
    "        train_x = torch.cat([train_x, X_new])\n",
    "        train_y = torch.cat([train_y, Y_new])\n",
    "        hv_vals.append(compute_hv(train_y))\n",
    "\n",
    "    return train_x, train_y, torch.tensor(hv_vals, device=DEVICE, dtype=DTYPE)\n",
    "\n",
    "\n",
    "# ---------------------------------\n",
    "# 6) Multi-run visualize that RUNS methods (requested)\n",
    "# ---------------------------------\n",
    "\n",
    "def visualize(*methods,\n",
    "              n_init: int = 5,\n",
    "              n_iter: int = 10,\n",
    "              sigma: float = 0.05,\n",
    "              seed: int = 123,\n",
    "              use_qnehvi: bool = True,\n",
    "              repeats: int = 3):\n",
    "    \"\"\"Run one or more runner functions (optionally repeated) and visualize results.\n",
    "\n",
    "    Each entry in `methods` can be either:\n",
    "      - a callable like `run_bo` or `run_random` (we'll use defaults), or\n",
    "      - a tuple (label, callable, kwargs_dict) for custom params per method.\n",
    "\n",
    "    Returns a dict[label] -> mean HV array (on CPU) and shows mean±std bands.\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    import torch\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    if len(methods) == 0:\n",
    "        methods = (\n",
    "            (\"BO-qNEHVI-m32_ard_indep2\", run_bo, {\"n_init\": n_init, \"n_iter\": n_iter, \"sigma\": sigma, \"seed\": seed, \"use_qnehvi\": use_qnehvi, \"preset\": \"m32_ard_indep2\"}),\n",
    "            (\"BO-qNEHVI-m52_indep2\",    run_bo, {\"n_init\": n_init, \"n_iter\": n_iter, \"sigma\": sigma, \"seed\": seed, \"use_qnehvi\": use_qnehvi, \"preset\": \"m52_indep2\"}),\n",
    "            (\"BO-qNEHVI-m52_ard_indep2\",run_bo, {\"n_init\": n_init, \"n_iter\": n_iter, \"sigma\": sigma, \"seed\": seed, \"use_qnehvi\": use_qnehvi, \"preset\": \"m52_ard_indep2\"}),\n",
    "            (\"Random\",                  run_random, {\"n_init\": n_init, \"n_iter\": n_iter, \"sigma\": sigma, \"seed\": seed}),\n",
    "        )\n",
    "\n",
    "    # Normalize methods into (label, fn, kwargs)\n",
    "    norm_methods = []\n",
    "    auto_seed = seed\n",
    "    for m in methods:\n",
    "        if callable(m):\n",
    "            label = m.__name__\n",
    "            kwargs = {\"n_init\": n_init, \"n_iter\": n_iter, \"sigma\": sigma, \"seed\": auto_seed}\n",
    "            if m is run_bo:\n",
    "                kwargs[\"use_qnehvi\"] = use_qnehvi\n",
    "            norm_methods.append((label, m, kwargs))\n",
    "            auto_seed += 1\n",
    "        else:\n",
    "            label, fn, kwargs = m\n",
    "            if \"seed\" not in kwargs:\n",
    "                kwargs = {**kwargs, \"seed\": auto_seed}\n",
    "                auto_seed += 1\n",
    "            norm_methods.append((label, fn, kwargs))\n",
    "\n",
    "    # Run each method `repeats` times with different seeds; collect results\n",
    "    results_by_label = {label: [] for (label, _, _) in norm_methods}\n",
    "    for label, fn, base_kwargs in norm_methods:\n",
    "        base_seed = int(base_kwargs.get(\"seed\", seed))\n",
    "        for r in range(repeats):\n",
    "            kw = dict(base_kwargs)\n",
    "            kw[\"seed\"] = base_seed + r  # different seed each repeat\n",
    "            X, Y, HV = fn(**kw)\n",
    "            results_by_label[label].append((X, Y, HV))\n",
    "\n",
    "    # Combined Hypervolume plot with mean ± std\n",
    "    plt.figure()\n",
    "    hv_curves_mean = {}\n",
    "    for label, runs in results_by_label.items():\n",
    "        lengths = [int(run[2].shape[0]) for run in runs]\n",
    "        T = min(lengths)\n",
    "        import numpy as np\n",
    "        hv_stack = np.stack([run[2].detach().cpu().numpy()[:T] for run in runs], axis=0)  # (R, T)\n",
    "        mean = hv_stack.mean(axis=0)\n",
    "        std = hv_stack.std(axis=0)\n",
    "\n",
    "        hv_curves_mean[label] = mean\n",
    "        x = np.arange(T)\n",
    "        plt.plot(x, mean, marker=\"o\", label=label)\n",
    "        plt.fill_between(x, mean - std, mean + std, alpha=0.2)\n",
    "\n",
    "    plt.xlabel(\"Iteration\"); plt.ylabel(\"Hypervolume (maximization space)\")\n",
    "    plt.title(f\"Hypervolume vs Iteration — comparison (repeats={repeats})\")\n",
    "    plt.legend(); plt.tight_layout()\n",
    "\n",
    "    # Per-method scatter of observations & Pareto (minimization), fixed axes & aspect\n",
    "    for label, runs in results_by_label.items():\n",
    "        Ys = torch.cat([run[1] for run in runs], dim=0)\n",
    "        Ymin = (1.0 - Ys).clamp(0.0, 1.0)\n",
    "        nd = is_non_dominated(Ys)\n",
    "        Y_nd = Ymin[nd]\n",
    "\n",
    "        Ymin = Ymin.detach().cpu()\n",
    "        Y_nd = Y_nd.detach().cpu()\n",
    "\n",
    "        plt.figure()\n",
    "        plt.scatter(Ymin[:, 0], Ymin[:, 1], alpha=0.35, label=f\"{label} obs (all repeats)\")\n",
    "        plt.scatter(Y_nd[:, 0], Y_nd[:, 1], marker=\"*\", s=140, label=f\"{label} Pareto (merged)\")\n",
    "        plt.xlim(0.0, 1.0); plt.ylim(0.0, 1.0)\n",
    "        plt.gca().set_aspect('equal', adjustable='box')\n",
    "        plt.gca().invert_xaxis(); plt.gca().invert_yaxis()\n",
    "        plt.xlabel(\"Size (normalized) ↓\"); plt.ylabel(\"PDI (normalized) ↓\")\n",
    "        plt.title(f\"Observations & Pareto — {label} (repeats={repeats})\")\n",
    "        plt.legend(); plt.tight_layout()\n",
    "\n",
    "    plt.show()\n",
    "    return hv_curves_mean\n",
    "\n",
    "\n",
    "# ---------------------------------\n",
    "# 7) visual_plus: per-iteration surrogate switching (policy-driven)\n",
    "# ---------------------------------\n",
    "\n",
    "def random_selector(it, train_x, train_y, presets, **kwargs):\n",
    "    \"\"\"Stateless random pick among available presets.\"\"\"\n",
    "    import random\n",
    "    return random.choice(presets)\n",
    "\n",
    "\n",
    "def hybrid_rule_selector(\n",
    "    it,\n",
    "    train_x,\n",
    "    train_y,\n",
    "    presets,\n",
    "    *,\n",
    "    hv=None,\n",
    "    n_iter=None,\n",
    "    state=None,\n",
    "    stagnation_N: int = 3,\n",
    "    success_eps: float = 0.0,\n",
    "    **kwargs,\n",
    "):\n",
    "    \"\"\"Hybrid, phase-based rule selector with stagnation-aware switching.\n",
    "\n",
    "    Phases by budget fraction f = it / n_iter:\n",
    "      - Early   (0–30%): prefer [\"rbf_iso\", \"m52_indep2\"]\n",
    "      - Middle  (30–70%): prefer [\"m52_ard_indep2\"]\n",
    "      - Late    (70–100%): prefer [\"m32_ard_indep2\"]\n",
    "\n",
    "    Rules:\n",
    "      - If HV improves (> success_eps) from last step, keep current model (if valid\n",
    "        for the phase), otherwise switch to the phase's primary choice.\n",
    "      - If HV stagnates for `stagnation_N` consecutive iterations, switch within\n",
    "        the phase's allowed set (toggle if 2 options, otherwise stay on the sole option).\n",
    "      - If entering a new phase and current is not in the allowed set, switch immediately\n",
    "        to the phase primary.\n",
    "\n",
    "    The `state` dict is mutated in-place to persist across iterations:\n",
    "      state = {\"current\": Optional[str], \"stagnant\": int}\n",
    "    \"\"\"\n",
    "    if state is None:\n",
    "        state = {}\n",
    "    current = state.get(\"current\")\n",
    "    stagnant = int(state.get(\"stagnant\", 0))\n",
    "\n",
    "    # Determine budget fraction & phase\n",
    "    f = 0.0 if (n_iter is None or n_iter <= 0) else it / float(n_iter)\n",
    "\n",
    "    early = [\"rbf_iso\", \"m52_indep2\"]\n",
    "    middle = [\"m52_ard_indep2\"]\n",
    "    late = [\"m32_ard_indep2\"]\n",
    "\n",
    "    def allowed(cands):\n",
    "        return [c for c in cands if c in presets]\n",
    "\n",
    "    if f < 0.30:\n",
    "        phase_opts = allowed(early) or presets\n",
    "    elif f < 0.70:\n",
    "        phase_opts = allowed(middle) or presets\n",
    "    else:\n",
    "        phase_opts = allowed(late) or presets\n",
    "\n",
    "    # Improvement / stagnation\n",
    "    improving = False\n",
    "    if isinstance(hv, list) and len(hv) >= 2:\n",
    "        improving = (hv[-1] - hv[-2]) > success_eps\n",
    "\n",
    "    # If current invalid for phase, reset to primary\n",
    "    if current not in phase_opts:\n",
    "        current = phase_opts[0]\n",
    "        stagnant = 0\n",
    "        state[\"current\"], state[\"stagnant\"] = current, stagnant\n",
    "        return current\n",
    "\n",
    "    if improving:\n",
    "        stagnant = 0\n",
    "        state[\"current\"], state[\"stagnant\"] = current, stagnant\n",
    "        return current\n",
    "\n",
    "    # Not improving\n",
    "    stagnant += 1\n",
    "    if stagnant >= stagnation_N:\n",
    "        if len(phase_opts) >= 2:\n",
    "            current = phase_opts[1] if current == phase_opts[0] else phase_opts[0]\n",
    "        else:\n",
    "            current = phase_opts[0]\n",
    "        stagnant = 0\n",
    "\n",
    "    state[\"current\"], state[\"stagnant\"] = current, stagnant\n",
    "    return current\n",
    "\n",
    "\n",
    "def fixed_model_selector(model_name: str):\n",
    "    \"\"\"Factory: returns a selector that always picks `model_name`.\n",
    "    If `model_name` is not in `presets`, fall back to the first available.\n",
    "    \"\"\"\n",
    "    def _sel(it, train_x, train_y, presets, **kwargs):\n",
    "        return model_name if model_name in presets else (presets[0] if len(presets) else model_name)\n",
    "    _sel.__name__ = f\"fixed_{model_name}\"\n",
    "    return _sel\n",
    "\n",
    "    if improving:\n",
    "        stagnant = 0\n",
    "        state[\"current\"], state[\"stagnant\"] = current, stagnant\n",
    "        return current\n",
    "\n",
    "    # Not improving\n",
    "    stagnant += 1\n",
    "    if stagnant >= stagnation_N:\n",
    "        if len(phase_opts) >= 2:\n",
    "            current = phase_opts[1] if current == phase_opts[0] else phase_opts[0]\n",
    "        else:\n",
    "            current = phase_opts[0]\n",
    "        stagnant = 0\n",
    "\n",
    "    state[\"current\"], state[\"stagnant\"] = current, stagnant\n",
    "    return current\n",
    "\n",
    "\n",
    "def visual_plus(\n",
    "    presets=(\"m52_ard_indep2\", \"m32_ard_indep2\", \"rbf_iso\", \"m52_indep2\"),\n",
    "    selector=random_selector,\n",
    "    n_init: int = 8,\n",
    "    n_iter: int = 20,\n",
    "    sigma: float = 0.05,\n",
    "    seed: int = 123,\n",
    "    use_qnehvi: bool = True,\n",
    "    repeats: int = 3,\n",
    "    success_eps: float = 0.0,\n",
    "    eval_sigma: float = 0.0,\n",
    "    selector_kwargs: dict | None = None,\n",
    "    plot: bool = True,\n",
    "):\n",
    "    \"\"\"Per-iteration surrogate switching with repeats → mean ± std HV bands + policy accuracy.\n",
    "\n",
    "    Policy accuracy: At each iteration, simulate **each** surrogate's suggested candidate on the\n",
    "    current dataset and pick the surrogate with the largest simulated HV gain (using `eval_sigma` noise).\n",
    "    A success is counted iff the selector's pick equals that simulated-best surrogate.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    (hv_mean_tensor, hv_std_tensor, picks_iter_last, picks_points_last, best_iter_last, policy_acc_mean, policy_acc_std)\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    from surrogates import Surrogate, PRESETS\n",
    "\n",
    "    def hv_of(Yt: Tensor) -> float:\n",
    "        return float(Hypervolume(ref_point=REF_POINT).compute(Yt[is_non_dominated(Yt)]))\n",
    "\n",
    "    def run_once(seed_local: int):\n",
    "        torch.manual_seed(seed_local); torch.cuda.manual_seed_all(seed_local)\n",
    "        X = draw_sobol_samples(bounds=bounds, n=1, q=n_init, seed=seed_local).squeeze(0)\n",
    "        X = unnormalize(X, bounds=bounds)\n",
    "        Y = oracle_noisy(X, sigma=sigma, seed=seed_local)\n",
    "        sgs = {}\n",
    "        picks_iter, picks_points = [], [\"init\"] * int(X.shape[0])\n",
    "        selector_state = {\"current\": None, \"stagnant\": 0}\n",
    "        HV = [hv_of(Y)]\n",
    "        correct_flags = []\n",
    "        best_iter = []\n",
    "\n",
    "        for it in range(n_iter):\n",
    "            hv_now = HV[-1]\n",
    "            gains, cands = {}, {}\n",
    "\n",
    "            # Fit/update ALL candidates on current data & simulate one-step gain\n",
    "            for name in presets:\n",
    "                try:\n",
    "                    if name not in sgs:\n",
    "                        cfg = PRESETS[name]; cfg.device = DEVICE; cfg.dtype = DTYPE\n",
    "                        sg = Surrogate(cfg)\n",
    "                        sg.build(normalize(X, bounds), Y)\n",
    "                        sgs[name] = sg\n",
    "                    else:\n",
    "                        sgs[name].update(normalize(X, bounds), Y)\n",
    "\n",
    "                    Xp = propose_candidates(sgs[name].model, X, use_qnehvi=use_qnehvi, q=BATCH_Q)\n",
    "                    Yp = oracle_noisy(Xp, sigma=eval_sigma)\n",
    "                    gains[name] = hv_of(torch.cat([Y, Yp])) - hv_now\n",
    "                    cands[name] = (Xp, Yp)\n",
    "                except Exception:\n",
    "                    gains[name] = float(\"-inf\")\n",
    "                    cands[name] = None\n",
    "\n",
    "            # Best surrogate under simulated gain\n",
    "            best_name = max(gains, key=gains.get)\n",
    "            best_iter.append(best_name)\n",
    "\n",
    "            # Selector chooses the actual surrogate (pass history & state)\n",
    "            if selector:\n",
    "                pick = selector(\n",
    "                    it,\n",
    "                    X,\n",
    "                    Y,\n",
    "                    presets,\n",
    "                    hv=HV,\n",
    "                    n_iter=n_iter,\n",
    "                    state=selector_state,\n",
    "                    success_eps=success_eps,\n",
    "                    **(selector_kwargs or {}),\n",
    "                )\n",
    "            else:\n",
    "                pick = presets[0]\n",
    "            picks_iter.append(pick)\n",
    "\n",
    "            # Execute chosen surrogate (fallbacks if necessary)\n",
    "            if cands.get(pick) is None:\n",
    "                alt = best_name if cands.get(best_name) is not None else None\n",
    "                if alt is None:\n",
    "                    X_new = torch.rand(BATCH_Q, DIM, dtype=DTYPE, device=DEVICE)\n",
    "                    Y_new = oracle_noisy(X_new, sigma=sigma)\n",
    "                else:\n",
    "                    X_new, _ = cands[alt]\n",
    "                    Y_new = oracle_noisy(X_new, sigma=sigma)\n",
    "            else:\n",
    "                X_new, _ = cands[pick]\n",
    "                Y_new = oracle_noisy(X_new, sigma=sigma)\n",
    "\n",
    "            X = torch.cat([X, X_new]); Y = torch.cat([Y, Y_new])\n",
    "            picks_points += [pick] * int(X_new.shape[0])\n",
    "            HV.append(hv_of(Y))\n",
    "\n",
    "            # Policy classification accuracy (pick equals simulated-best)\n",
    "            correct_flags.append(1 if (pick == best_name) else 0)\n",
    "\n",
    "        return X, Y, torch.tensor(HV, device=DEVICE, dtype=DTYPE), picks_iter, picks_points, correct_flags, best_iter\n",
    "\n",
    "    # ---- Run repeats ----\n",
    "    runs = [run_once(seed + r) for r in range(repeats)]\n",
    "\n",
    "    # HV stats\n",
    "    T = min(int(hv.shape[0]) for (_, _, hv, _, _, _, _) in runs)\n",
    "    import numpy as np\n",
    "    hv_stack = np.stack([hv.detach().cpu().numpy()[:T] for (_, _, hv, _, _, _, _) in runs], axis=0)\n",
    "    hv_mean = hv_stack.mean(axis=0); hv_std = hv_stack.std(axis=0)\n",
    "\n",
    "    # Policy accuracy across repeats\n",
    "    accs = [float(np.mean(cf)) for (_, _, _, _, _, cf, _) in runs]\n",
    "    policy_acc_mean = float(np.mean(accs)) if len(accs) else float('nan')\n",
    "    policy_acc_std  = float(np.std(accs)) if len(accs) else float('nan')\n",
    "\n",
    "    # Use last run for qualitative colored plots\n",
    "    X_last, Y_last, HV_last, picks_iter_last, picks_points_last, _, best_iter_last = runs[-1]\n",
    "\n",
    "    if plot:\n",
    "        # ---- Plot HV mean ± std; overlay last run markers colored by surrogate ----\n",
    "        plt.figure()\n",
    "        xs = np.arange(T)\n",
    "        plt.plot(xs, hv_mean, color=\"black\", label=\"HV mean\")\n",
    "        plt.fill_between(xs, hv_mean - hv_std, hv_mean + hv_std, alpha=0.2, label=\"±1σ\")\n",
    "        cmap = plt.get_cmap(\"tab10\"); colors = {p: cmap(i % 10) for i, p in enumerate(presets)}\n",
    "        hv_np_last = HV_last.detach().cpu().numpy()[:T]\n",
    "        for i in range(1, T):\n",
    "            name = picks_iter_last[i-1] if (i-1) < len(picks_iter_last) else picks_iter_last[-1]\n",
    "            plt.scatter(i, hv_np_last[i], color=colors.get(name, \"gray\"), s=36)\n",
    "        plt.xlabel(\"Iteration\"); plt.ylabel(\"Hypervolume (maximization space)\")\n",
    "        plt.title(f\"HV vs Iteration — mean±std (repeats={repeats})\")\n",
    "        handles = [plt.Line2D([0],[0], marker='o', linestyle='', color=colors[p], label=p) for p in presets]\n",
    "        plt.legend(handles=[plt.Line2D([0],[0], color='black', label='mean')] + handles, title=\"Surrogate\", loc='best')\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # ---- Policy accuracy bar ----\n",
    "        plt.figure()\n",
    "        plt.bar([0], [policy_acc_mean], yerr=[policy_acc_std], alpha=0.6, capsize=4)\n",
    "        plt.xticks([0], [\"Policy accuracy\"])\n",
    "        plt.ylim(0, 1)\n",
    "        plt.ylabel(\"Fraction of iterations correct\")\n",
    "        plt.title(f\"Selector accuracy (mean ± std over {repeats} repeats)\")\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # ---- Scatter of last run, points colored by proposing surrogate ----\n",
    "        Ymin = (1.0 - Y_last).clamp(0.0, 1.0)\n",
    "        nd = is_non_dominated(Y_last)\n",
    "        Y_nd = Ymin[nd]\n",
    "        Ymin_cpu = Ymin.detach().cpu(); Y_nd_cpu = Y_nd.detach().cpu()\n",
    "        plt.figure()\n",
    "        for idx in range(Ymin_cpu.shape[0]):\n",
    "            lab = picks_points_last[idx] if idx < len(picks_points_last) else \"init\"\n",
    "            plt.scatter([Ymin_cpu[idx,0]],[Ymin_cpu[idx,1]], alpha=0.5, color=colors.get(lab, \"gray\"), s=18)\n",
    "        plt.scatter(Y_nd_cpu[:,0], Y_nd_cpu[:,1], marker='*', s=140, color='k', label='Pareto (last run)')\n",
    "        plt.xlim(0,1); plt.ylim(0,1); plt.gca().set_aspect('equal', adjustable='box')\n",
    "        plt.gca().invert_xaxis(); plt.gca().invert_yaxis()\n",
    "        plt.xlabel(\"Size (normalized) ↓\"); plt.ylabel(\"PDI (normalized) ↓\")\n",
    "        plt.title(\"Observations colored by chosen surrogate — last run\")\n",
    "        plt.legend(); plt.tight_layout(); plt.show()\n",
    "\n",
    "        # Print lists for quick inspection\n",
    "        try:\n",
    "            print(\"Best (simulated) surrogate per iteration:\", best_iter_last)\n",
    "            print(\"Chosen (selector) surrogate per iteration:\", picks_iter_last)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    return (\n",
    "        torch.tensor(hv_mean, device=DEVICE, dtype=DTYPE),\n",
    "        torch.tensor(hv_std, device=DEVICE, dtype=DTYPE),\n",
    "        picks_iter_last,\n",
    "        picks_points_last,\n",
    "        best_iter_last,\n",
    "        policy_acc_mean,\n",
    "        policy_acc_std,\n",
    "    )\n",
    "\n",
    "\n",
    "def visual_plus_compare(\n",
    "    selectors: dict | None = None,\n",
    "    *,\n",
    "    presets=(\"m52_ard_indep2\", \"m32_ard_indep2\", \"rbf_iso\", \"m52_indep2\"),\n",
    "    n_init: int = 3,\n",
    "    n_iter: int = 20,\n",
    "    sigma: float = 0.05,\n",
    "    seed: int = 123,\n",
    "    use_qnehvi: bool = True,\n",
    "    repeats: int = 3,\n",
    "    success_eps: float = 0.0,\n",
    "    eval_sigma: float = 0.0,\n",
    "    campaign_model: str | None = \"m52_ard_indep2\",\n",
    "):\n",
    "    \"\"\"Compare multiple selector policies on the same problem (HV mean±std curves).\n",
    "\n",
    "    `selectors` maps a display name -> selector function. By default compares\n",
    "    Random vs Hybrid.\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    if selectors is None:\n",
    "        selectors = {\n",
    "            \"Random\": random_selector,\n",
    "            \"Hybrid\": hybrid_rule_selector,\n",
    "        }\n",
    "        if campaign_model is not None:\n",
    "            selectors[f\"Campaign: {campaign_model}\"] = fixed_model_selector(campaign_model)\n",
    "\n",
    "    curves = {}\n",
    "    for name, sel in selectors.items():\n",
    "        hv_mean, hv_std, _, _, _, acc_mean, acc_std = visual_plus(\n",
    "            presets=presets,\n",
    "            selector=sel,\n",
    "            n_init=n_init,\n",
    "            n_iter=n_iter,\n",
    "            sigma=sigma,\n",
    "            seed=seed,\n",
    "            use_qnehvi=use_qnehvi,\n",
    "            repeats=repeats,\n",
    "            success_eps=success_eps,\n",
    "            eval_sigma=eval_sigma,\n",
    "            selector_kwargs=None,\n",
    "            plot=False,\n",
    "        )\n",
    "        curves[name] = (hv_mean.detach().cpu().numpy(), hv_std.detach().cpu().numpy(), acc_mean, acc_std)\n",
    "\n",
    "    # Plot combined HV curves\n",
    "    plt.figure()\n",
    "    for name, (m, s, acc_m, acc_s) in curves.items():\n",
    "        xs = np.arange(len(m))\n",
    "        plt.plot(xs, m, marker=\"o\", label=f\"{name} (acc={acc_m:.2f}±{acc_s:.2f})\")\n",
    "        plt.fill_between(xs, m - s, m + s, alpha=0.2)\n",
    "    plt.xlabel(\"Iteration\"); plt.ylabel(\"Hypervolume (maximization space)\")\n",
    "    plt.title(f\"Policy comparison (repeats={repeats})\")\n",
    "    plt.legend(); plt.tight_layout(); plt.show()\n",
    "\n",
    "# Example usage:\n",
    "# hvm, hvs, picks, tags, best, acc_m, acc_s = visual_plus(selector=hybrid_rule_selector, repeats=3, seed=2355632)\n",
    "# visual_plus_compare(repeats=20, seed=765)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e6e741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# Sequence mining for LSTM data\n",
    "# ============================\n",
    "import torch, numpy as np, json, os, traceback\n",
    "from typing import List, Tuple, Dict, Any\n",
    "\n",
    "# Global sink (append-only) – survives errors inside the loop\n",
    "MINED_DATASET: List[Dict[str, Any]] = []\n",
    "\n",
    "@torch.no_grad()\n",
    "def _hv_of(Y: torch.Tensor) -> float:\n",
    "    mask = is_non_dominated(Y)\n",
    "    return float(Hypervolume(ref_point=REF_POINT).compute(Y[mask]))\n",
    "\n",
    "def _sample_sequence(\n",
    "    models: Tuple[str, ...],\n",
    "    L: int,\n",
    "    sampler: str = \"iid_uniform\",\n",
    "    rng: np.random.Generator | None = None,\n",
    "    dirichlet_alpha: float = 1.0,\n",
    ") -> Tuple[str, ...]:\n",
    "    \"\"\"Return a random sequence of length L from `models`.\"\"\"\n",
    "    rng = rng or np.random.default_rng()\n",
    "    if sampler == \"iid_uniform\":\n",
    "        idx = rng.integers(0, len(models), size=L)\n",
    "        return tuple(models[i] for i in idx)\n",
    "    elif sampler == \"dirichlet_per_sequence\":\n",
    "        # Draw per-sequence category probabilities, then sample each position\n",
    "        p = rng.dirichlet([dirichlet_alpha] * len(models))\n",
    "        idx = rng.choice(len(models), size=L, p=p)\n",
    "        return tuple(models[i] for i in idx)\n",
    "    elif sampler == \"phase_bias\":\n",
    "        # Example: explore→balance→exploit phases in thirds\n",
    "        thirds = [int(np.ceil(L/3)), int(np.floor(L/3)), L - int(np.ceil(L/3)) - int(np.floor(L/3))]\n",
    "        early, mid, late = thirds\n",
    "        early_set  = [m for m in (\"rbf_iso\", \"m52_indep2\") if m in models] or list(models)\n",
    "        middle_set = [m for m in (\"m52_ard_indep2\",) if m in models] or list(models)\n",
    "        late_set   = [m for m in (\"m32_ard_indep2\",) if m in models] or list(models)\n",
    "        seq = []\n",
    "        seq += list(rng.choice(early_set,  size=early))\n",
    "        seq += list(rng.choice(middle_set, size=mid))\n",
    "        seq += list(rng.choice(late_set,   size=late))\n",
    "        return tuple(seq)\n",
    "    else:\n",
    "        raise ValueError(\"sampler must be one of: iid_uniform | dirichlet_per_sequence | phase_bias\")\n",
    "\n",
    "def mine_sequences_dataset(\n",
    "    *,\n",
    "    n_iter: int = 20,                # sequence length\n",
    "    n_samples: int = 500,            # how many sequences to generate\n",
    "    n_init: int = 3,\n",
    "    sigma: float = 0.05,\n",
    "    seed: int = 12345,\n",
    "    use_qnehvi: bool = True,\n",
    "    models: Tuple[str, ...] = (\"m52_ard_indep2\",\"m32_ard_indep2\",\"rbf_iso\",\"m52_indep2\",\"m52_ard\"),\n",
    "    sampler: str = \"iid_uniform\",    # or 'dirichlet_per_sequence' / 'phase_bias'\n",
    "    dirichlet_alpha: float = 1.0,\n",
    "    save_path: str | None = \"mined_sequences.pt\",   # set None to disable\n",
    "    save_every: int = 10,\n",
    "    log_every: int = 10,\n",
    "    strict_presets: bool = True,     # drop unknown model names when True\n",
    "    max_retries_per_step: int = 1,   # retries if acq optimization fails; then fallback to random\n",
    ") -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Generate `n_samples` sequences of length `n_iter` using random/fair sampling.\n",
    "    For each sequence, run a BO campaign that *follows* that surrogate order.\n",
    "\n",
    "    Returns MINED_DATASET (also autosaved every `save_every` sequences if save_path is set).\n",
    "\n",
    "    Each entry in MINED_DATASET:\n",
    "      {\n",
    "        'seed': int,\n",
    "        'seq': [str, ...],                 # chosen surrogate names (length n_iter)\n",
    "        'models': [str, ...],              # model universe used\n",
    "        'n_init': int,\n",
    "        'sigma': float,\n",
    "        'use_qnehvi': bool,\n",
    "        'X_full': np.ndarray [n_init+n_iter, DIM],\n",
    "        'Y_full': np.ndarray [n_init+n_iter, 2],\n",
    "        'HV': np.ndarray [n_iter+1],       # includes HV after init\n",
    "        'X_iter': [np.ndarray (1,DIM),...],# per-iteration new X (q=1)\n",
    "        'Y_iter': [np.ndarray (1,2),...],  # per-iteration new Y\n",
    "        'error': Optional[str],            # present if a fatal error occurred\n",
    "      }\n",
    "    \"\"\"\n",
    "    from surrogates import Surrogate, PRESETS\n",
    "\n",
    "    # Filter models to available presets\n",
    "    if strict_presets:\n",
    "        models = tuple([m for m in models if m in PRESETS])\n",
    "        if len(models) == 0:\n",
    "            raise ValueError(\"No valid models after filtering against PRESETS.\")\n",
    "\n",
    "    rng = np.random.default_rng(seed)\n",
    "    torch.manual_seed(seed); torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "    for k in range(n_samples):\n",
    "        seq = _sample_sequence(models=models, L=n_iter, sampler=sampler, rng=rng, dirichlet_alpha=dirichlet_alpha)\n",
    "        run_seed = seed + k  # different campaign seed per sample\n",
    "\n",
    "        try:\n",
    "            # Initialize\n",
    "            torch.manual_seed(run_seed); torch.cuda.manual_seed_all(run_seed)\n",
    "            X = draw_sobol_samples(bounds=bounds, n=1, q=n_init, seed=run_seed).squeeze(0)\n",
    "            X = unnormalize(X, bounds=bounds)\n",
    "            Y = oracle_noisy(X, sigma=sigma, seed=run_seed)\n",
    "            HV = [_hv_of(Y)]\n",
    "\n",
    "            # Cache built surrogates by name (re-fit/update on current data when used)\n",
    "            sg_cache: Dict[str, Surrogate] = {}\n",
    "            X_iters, Y_iters = [], []\n",
    "\n",
    "            # Rollout the sequence\n",
    "            for t, name in enumerate(seq):\n",
    "                # Build/update model\n",
    "                attempt = 0\n",
    "                while True:\n",
    "                    try:\n",
    "                        if (name not in sg_cache):\n",
    "                            cfg = PRESETS[name]; cfg.device = DEVICE; cfg.dtype = DTYPE\n",
    "                            sg = Surrogate(cfg)\n",
    "                            sg.build(normalize(X, bounds), Y)\n",
    "                            sg_cache[name] = sg\n",
    "                        else:\n",
    "                            sg_cache[name].update(normalize(X, bounds), Y, warm_start=True)\n",
    "                        model = sg_cache[name].model\n",
    "\n",
    "                        # Propose and observe\n",
    "                        X_new = propose_candidates(model, X, use_qnehvi=use_qnehvi, q=1)\n",
    "                        Y_new = oracle_noisy(X_new, sigma=sigma)\n",
    "                        break\n",
    "                    except Exception:\n",
    "                        attempt += 1\n",
    "                        if attempt > max_retries_per_step:\n",
    "                            # fallback to random step to keep dataset growing\n",
    "                            X_new = torch.rand(1, DIM, device=DEVICE, dtype=DTYPE)\n",
    "                            Y_new = oracle_noisy(X_new, sigma=sigma)\n",
    "                            break\n",
    "                        # else retry once (e.g., transient optimizer failure)\n",
    "\n",
    "                X = torch.cat([X, X_new], dim=0)\n",
    "                Y = torch.cat([Y, Y_new], dim=0)\n",
    "                X_iters.append(X_new.detach().cpu().numpy())\n",
    "                Y_iters.append(Y_new.detach().cpu().numpy())\n",
    "                HV.append(_hv_of(Y))\n",
    "\n",
    "            entry = {\n",
    "                \"seed\": run_seed,\n",
    "                \"seq\": list(seq),\n",
    "                \"models\": list(models),\n",
    "                \"n_init\": int(n_init),\n",
    "                \"sigma\": float(sigma),\n",
    "                \"use_qnehvi\": bool(use_qnehvi),\n",
    "                \"X_full\": X.detach().cpu().numpy(),\n",
    "                \"Y_full\": Y.detach().cpu().numpy(),\n",
    "                \"HV\": np.asarray(HV, dtype=float),\n",
    "                \"X_iter\": X_iters,\n",
    "                \"Y_iter\": Y_iters,\n",
    "            }\n",
    "            MINED_DATASET.append(entry)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"exception has been seen 2\")\n",
    "            # Record partial progress with an error message; continue mining\n",
    "            entry = {\n",
    "                \"seed\": run_seed,\n",
    "                \"seq\": list(seq),\n",
    "                \"models\": list(models),\n",
    "                \"n_init\": int(n_init),\n",
    "                \"sigma\": float(sigma),\n",
    "                \"use_qnehvi\": bool(use_qnehvi),\n",
    "                \"error\": f\"{type(e).__name__}: {str(e)}\",\n",
    "                \"traceback\": traceback.format_exc(limit=1),\n",
    "            }\n",
    "            MINED_DATASET.append(entry)\n",
    "\n",
    "        # Autosave & log\n",
    "        if save_path and ((k + 1) % save_every == 0):\n",
    "            try:\n",
    "                torch.save(MINED_DATASET, save_path)  # robust pickle\n",
    "            except Exception:\n",
    "                # Fallback to simple npz: strip tensors to arrays\n",
    "                safe = [{\n",
    "                    **{k: v for k, v in d.items() if k not in (\"traceback\",)},\n",
    "                    \"X_full\": d.get(\"X_full\", None),\n",
    "                    \"Y_full\": d.get(\"Y_full\", None),\n",
    "                    \"HV\": d.get(\"HV\", None),\n",
    "                    \"X_iter\": d.get(\"X_iter\", None),\n",
    "                    \"Y_iter\": d.get(\"Y_iter\", None),\n",
    "                } for d in MINED_DATASET]\n",
    "                np.savez_compressed(os.path.splitext(save_path)[0] + \".npz\", data=safe, allow_pickle=True)\n",
    "\n",
    "        if (k + 1) % log_every == 0:\n",
    "            print(f\"[mine_sequences_dataset] Collected {k+1}/{n_samples} sequences.\")\n",
    "\n",
    "    # Final save\n",
    "    if save_path:\n",
    "        try:\n",
    "            torch.save(MINED_DATASET, save_path)\n",
    "        except Exception:\n",
    "            np.savez_compressed(os.path.splitext(save_path)[0] + \".npz\", data=MINED_DATASET, allow_pickle=True)\n",
    "\n",
    "    return MINED_DATASET\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4a0895a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mine_sequences_dataset] Collected 50/10000 sequences.\n",
      "[mine_sequences_dataset] Collected 100/10000 sequences.\n",
      "[mine_sequences_dataset] Collected 150/10000 sequences.\n",
      "[mine_sequences_dataset] Collected 200/10000 sequences.\n",
      "[mine_sequences_dataset] Collected 250/10000 sequences.\n",
      "[mine_sequences_dataset] Collected 300/10000 sequences.\n",
      "[mine_sequences_dataset] Collected 350/10000 sequences.\n",
      "[mine_sequences_dataset] Collected 400/10000 sequences.\n",
      "[mine_sequences_dataset] Collected 450/10000 sequences.\n",
      "[mine_sequences_dataset] Collected 500/10000 sequences.\n",
      "[mine_sequences_dataset] Collected 550/10000 sequences.\n",
      "[mine_sequences_dataset] Collected 600/10000 sequences.\n",
      "[mine_sequences_dataset] Collected 650/10000 sequences.\n",
      "[mine_sequences_dataset] Collected 700/10000 sequences.\n",
      "[mine_sequences_dataset] Collected 750/10000 sequences.\n",
      "[mine_sequences_dataset] Collected 800/10000 sequences.\n",
      "[mine_sequences_dataset] Collected 850/10000 sequences.\n",
      "[mine_sequences_dataset] Collected 900/10000 sequences.\n",
      "[mine_sequences_dataset] Collected 950/10000 sequences.\n",
      "[mine_sequences_dataset] Collected 1000/10000 sequences.\n",
      "[mine_sequences_dataset] Collected 1050/10000 sequences.\n",
      "[mine_sequences_dataset] Collected 1100/10000 sequences.\n",
      "[mine_sequences_dataset] Collected 1150/10000 sequences.\n",
      "[mine_sequences_dataset] Collected 1200/10000 sequences.\n",
      "[mine_sequences_dataset] Collected 1250/10000 sequences.\n",
      "[mine_sequences_dataset] Collected 1300/10000 sequences.\n",
      "[mine_sequences_dataset] Collected 1350/10000 sequences.\n",
      "[mine_sequences_dataset] Collected 1400/10000 sequences.\n",
      "[mine_sequences_dataset] Collected 1450/10000 sequences.\n",
      "[mine_sequences_dataset] Collected 1500/10000 sequences.\n",
      "[mine_sequences_dataset] Collected 1550/10000 sequences.\n",
      "[mine_sequences_dataset] Collected 1600/10000 sequences.\n",
      "[mine_sequences_dataset] Collected 1650/10000 sequences.\n",
      "[mine_sequences_dataset] Collected 1700/10000 sequences.\n",
      "[mine_sequences_dataset] Collected 1750/10000 sequences.\n",
      "[mine_sequences_dataset] Collected 1800/10000 sequences.\n",
      "[mine_sequences_dataset] Collected 1850/10000 sequences.\n",
      "[mine_sequences_dataset] Collected 1900/10000 sequences.\n",
      "[mine_sequences_dataset] Collected 1950/10000 sequences.\n",
      "[mine_sequences_dataset] Collected 2000/10000 sequences.\n",
      "[mine_sequences_dataset] Collected 2050/10000 sequences.\n",
      "[mine_sequences_dataset] Collected 2100/10000 sequences.\n",
      "[mine_sequences_dataset] Collected 2150/10000 sequences.\n",
      "[mine_sequences_dataset] Collected 2200/10000 sequences.\n",
      "[mine_sequences_dataset] Collected 2250/10000 sequences.\n",
      "[mine_sequences_dataset] Collected 2300/10000 sequences.\n",
      "[mine_sequences_dataset] Collected 2350/10000 sequences.\n",
      "[mine_sequences_dataset] Collected 2400/10000 sequences.\n",
      "[mine_sequences_dataset] Collected 2450/10000 sequences.\n",
      "[mine_sequences_dataset] Collected 2500/10000 sequences.\n",
      "[mine_sequences_dataset] Collected 2550/10000 sequences.\n",
      "[mine_sequences_dataset] Collected 2600/10000 sequences.\n",
      "[mine_sequences_dataset] Collected 2650/10000 sequences.\n",
      "[mine_sequences_dataset] Collected 2700/10000 sequences.\n",
      "[mine_sequences_dataset] Collected 2750/10000 sequences.\n",
      "[mine_sequences_dataset] Collected 2800/10000 sequences.\n",
      "[mine_sequences_dataset] Collected 2850/10000 sequences.\n",
      "[mine_sequences_dataset] Collected 2900/10000 sequences.\n",
      "[mine_sequences_dataset] Collected 2950/10000 sequences.\n",
      "[mine_sequences_dataset] Collected 3000/10000 sequences.\n",
      "[mine_sequences_dataset] Collected 3050/10000 sequences.\n",
      "[mine_sequences_dataset] Collected 3100/10000 sequences.\n",
      "[mine_sequences_dataset] Collected 3150/10000 sequences.\n",
      "[mine_sequences_dataset] Collected 3200/10000 sequences.\n",
      "[mine_sequences_dataset] Collected 3250/10000 sequences.\n",
      "[mine_sequences_dataset] Collected 3300/10000 sequences.\n",
      "[mine_sequences_dataset] Collected 3350/10000 sequences.\n",
      "[mine_sequences_dataset] Collected 3400/10000 sequences.\n",
      "[mine_sequences_dataset] Collected 3450/10000 sequences.\n",
      "[mine_sequences_dataset] Collected 3500/10000 sequences.\n",
      "[mine_sequences_dataset] Collected 3550/10000 sequences.\n",
      "[mine_sequences_dataset] Collected 3600/10000 sequences.\n",
      "[mine_sequences_dataset] Collected 3650/10000 sequences.\n",
      "[mine_sequences_dataset] Collected 3700/10000 sequences.\n",
      "[mine_sequences_dataset] Collected 3750/10000 sequences.\n",
      "[mine_sequences_dataset] Collected 3800/10000 sequences.\n",
      "[mine_sequences_dataset] Collected 3850/10000 sequences.\n",
      "[mine_sequences_dataset] Collected 3900/10000 sequences.\n",
      "[mine_sequences_dataset] Collected 3950/10000 sequences.\n",
      "[mine_sequences_dataset] Collected 4000/10000 sequences.\n",
      "[mine_sequences_dataset] Collected 4050/10000 sequences.\n",
      "[mine_sequences_dataset] Collected 4100/10000 sequences.\n",
      "[mine_sequences_dataset] Collected 4150/10000 sequences.\n",
      "[mine_sequences_dataset] Collected 4200/10000 sequences.\n",
      "[mine_sequences_dataset] Collected 4250/10000 sequences.\n",
      "[mine_sequences_dataset] Collected 4300/10000 sequences.\n",
      "[mine_sequences_dataset] Collected 4350/10000 sequences.\n",
      "[mine_sequences_dataset] Collected 4400/10000 sequences.\n",
      "[mine_sequences_dataset] Collected 4450/10000 sequences.\n",
      "[mine_sequences_dataset] Collected 4500/10000 sequences.\n",
      "[mine_sequences_dataset] Collected 4550/10000 sequences.\n",
      "[mine_sequences_dataset] Collected 4600/10000 sequences.\n",
      "[mine_sequences_dataset] Collected 4650/10000 sequences.\n",
      "[mine_sequences_dataset] Collected 4700/10000 sequences.\n",
      "[mine_sequences_dataset] Collected 4750/10000 sequences.\n",
      "[mine_sequences_dataset] Collected 4800/10000 sequences.\n",
      "[mine_sequences_dataset] Collected 4850/10000 sequences.\n",
      "[mine_sequences_dataset] Collected 4900/10000 sequences.\n",
      "[mine_sequences_dataset] Collected 4950/10000 sequences.\n",
      "[mine_sequences_dataset] Collected 5000/10000 sequences.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[34]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m warnings.filterwarnings(\u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m) \n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Mine 2,000 sequences of length 20 with iid-uniform sampling\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m dataset = \u001b[43mmine_sequences_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_iter\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m20\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_init\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43msigma\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.05\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m777\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43msampler\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43miid_uniform\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m              \u001b[49m\u001b[38;5;66;43;03m# or \"dirichlet_per_sequence\" / \"phase_bias\"\u001b[39;49;00m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43msave_path\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmined_sequences.pt\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m     \u001b[49m\u001b[38;5;66;43;03m# autosaves every 10 runs\u001b[39;49;00m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43msave_every\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlog_every\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 129\u001b[39m, in \u001b[36mmine_sequences_dataset\u001b[39m\u001b[34m(n_iter, n_samples, n_init, sigma, seed, use_qnehvi, models, sampler, dirichlet_alpha, save_path, save_every, log_every, strict_presets, max_retries_per_step)\u001b[39m\n\u001b[32m    126\u001b[39m model = sg_cache[name].model\n\u001b[32m    128\u001b[39m \u001b[38;5;66;03m# Propose and observe\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m129\u001b[39m X_new = \u001b[43mpropose_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_qnehvi\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_qnehvi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mq\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    130\u001b[39m Y_new = oracle_noisy(X_new, sigma=sigma)\n\u001b[32m    131\u001b[39m \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 196\u001b[39m, in \u001b[36mpropose_candidates\u001b[39m\u001b[34m(model, train_x, use_qnehvi, q)\u001b[39m\n\u001b[32m    188\u001b[39m     part = FastNondominatedPartitioning(ref_point=REF_POINT, Y=post_mean)\n\u001b[32m    189\u001b[39m     acq = qExpectedHypervolumeImprovement(\n\u001b[32m    190\u001b[39m         model=model,\n\u001b[32m    191\u001b[39m         ref_point=REF_POINT,\n\u001b[32m    192\u001b[39m         partitioning=part,\n\u001b[32m    193\u001b[39m         sampler=sampler,\n\u001b[32m    194\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m196\u001b[39m cand, _ = \u001b[43moptimize_acqf\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    197\u001b[39m \u001b[43m    \u001b[49m\u001b[43macq_function\u001b[49m\u001b[43m=\u001b[49m\u001b[43macq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    198\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[43m    \u001b[49m\u001b[43mq\u001b[49m\u001b[43m=\u001b[49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    200\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_restarts\u001b[49m\u001b[43m=\u001b[49m\u001b[43mNUM_RESTARTS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    201\u001b[39m \u001b[43m    \u001b[49m\u001b[43mraw_samples\u001b[49m\u001b[43m=\u001b[49m\u001b[43mRAW_SAMPLES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    202\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbatch_limit\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmaxiter\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m200\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    203\u001b[39m \u001b[43m    \u001b[49m\u001b[43msequential\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    204\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    205\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m unnormalize(cand.detach(), bounds=bounds)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/pol_env/lib/python3.11/site-packages/botorch/optim/optimize.py:732\u001b[39m, in \u001b[36moptimize_acqf\u001b[39m\u001b[34m(acq_function, bounds, q, num_restarts, raw_samples, options, inequality_constraints, equality_constraints, nonlinear_inequality_constraints, fixed_features, post_processing_func, batch_initial_conditions, return_best_only, gen_candidates, sequential, acq_function_sequence, ic_generator, timeout_sec, return_full_tree, retry_on_optimization_warning, **ic_gen_kwargs)\u001b[39m\n\u001b[32m    708\u001b[39m     gen_candidates = gen_candidates_scipy\n\u001b[32m    709\u001b[39m opt_acqf_inputs = OptimizeAcqfInputs(\n\u001b[32m    710\u001b[39m     acq_function=acq_function,\n\u001b[32m    711\u001b[39m     bounds=bounds,\n\u001b[32m   (...)\u001b[39m\u001b[32m    730\u001b[39m     acq_function_sequence=acq_function_sequence,\n\u001b[32m    731\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m732\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_optimize_acqf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopt_inputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mopt_acqf_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/pol_env/lib/python3.11/site-packages/botorch/optim/optimize.py:753\u001b[39m, in \u001b[36m_optimize_acqf\u001b[39m\u001b[34m(opt_inputs)\u001b[39m\n\u001b[32m    750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _optimize_acqf_sequential_q(opt_inputs=opt_inputs)\n\u001b[32m    752\u001b[39m \u001b[38;5;66;03m# Batch optimization (including the case q=1)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m753\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_optimize_acqf_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopt_inputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mopt_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/pol_env/lib/python3.11/site-packages/botorch/optim/optimize.py:457\u001b[39m, in \u001b[36m_optimize_acqf_batch\u001b[39m\u001b[34m(opt_inputs)\u001b[39m\n\u001b[32m    454\u001b[39m         batch_acq_values = torch.cat(batch_acq_values_list).flatten()\n\u001b[32m    455\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m batch_candidates, batch_acq_values, opt_warnings\n\u001b[32m--> \u001b[39m\u001b[32m457\u001b[39m batch_candidates, batch_acq_values, ws = \u001b[43m_optimize_batch_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    459\u001b[39m optimization_warning_raised = \u001b[38;5;28many\u001b[39m(\n\u001b[32m    460\u001b[39m     \u001b[38;5;28missubclass\u001b[39m(w.category, OptimizationWarning) \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m ws\n\u001b[32m    461\u001b[39m )\n\u001b[32m    462\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m optimization_warning_raised \u001b[38;5;129;01mand\u001b[39;00m opt_inputs.retry_on_optimization_warning:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/pol_env/lib/python3.11/site-packages/botorch/optim/optimize.py:434\u001b[39m, in \u001b[36m_optimize_acqf_batch.<locals>._optimize_batch_candidates\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    429\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m warnings.catch_warnings(record=\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m ws:\n\u001b[32m    430\u001b[39m     warnings.simplefilter(\u001b[33m\"\u001b[39m\u001b[33malways\u001b[39m\u001b[33m\"\u001b[39m, category=OptimizationWarning)\n\u001b[32m    431\u001b[39m     (\n\u001b[32m    432\u001b[39m         batch_candidates_curr,\n\u001b[32m    433\u001b[39m         batch_acq_values_curr,\n\u001b[32m--> \u001b[39m\u001b[32m434\u001b[39m     ) = \u001b[43mopt_inputs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgen_candidates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    435\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbatched_ics_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    436\u001b[39m \u001b[43m        \u001b[49m\u001b[43mopt_inputs\u001b[49m\u001b[43m.\u001b[49m\u001b[43macq_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    437\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlower_bounds\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlower_bounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    438\u001b[39m \u001b[43m        \u001b[49m\u001b[43mupper_bounds\u001b[49m\u001b[43m=\u001b[49m\u001b[43mupper_bounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    439\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgen_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    440\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfixed_features\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatched_fixed_features\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    441\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout_sec\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_sec\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    442\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mgen_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    443\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    444\u001b[39m opt_warnings += ws\n\u001b[32m    445\u001b[39m batch_candidates_list.append(batch_candidates_curr)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/pol_env/lib/python3.11/site-packages/botorch/generation/gen.py:235\u001b[39m, in \u001b[36mgen_candidates_scipy\u001b[39m\u001b[34m(initial_conditions, acquisition_function, lower_bounds, upper_bounds, inequality_constraints, equality_constraints, nonlinear_inequality_constraints, options, fixed_features, timeout_sec, use_parallel_mode)\u001b[39m\n\u001b[32m    227\u001b[39m l_bfgs_b_bounds = translate_bounds_for_lbfgsb(\n\u001b[32m    228\u001b[39m     lower_bounds=lower_bounds,\n\u001b[32m    229\u001b[39m     upper_bounds=upper_bounds,\n\u001b[32m    230\u001b[39m     num_features=clamped_candidates.shape[-\u001b[32m1\u001b[39m],\n\u001b[32m    231\u001b[39m     q=clamped_candidates.shape[\u001b[32m1\u001b[39m],\n\u001b[32m    232\u001b[39m )\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m threadpool_limits(limits=\u001b[32m1\u001b[39m, user_api=\u001b[33m\"\u001b[39m\u001b[33mblas\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m235\u001b[39m     xs, fs, results = \u001b[43mfmin_l_bfgs_b_batched\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    236\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf_np_wrapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfixed_features\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfixed_features\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# args is not necessary, done via the partial instead\u001b[39;49;00m\n\u001b[32m    238\u001b[39m \u001b[43m        \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatched_x0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# method=method, # method is not necessary as it is only l-bfgs-b\u001b[39;49;00m\n\u001b[32m    240\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# jac=with_grad, this is assumed to be true\u001b[39;49;00m\n\u001b[32m    241\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m=\u001b[49m\u001b[43ml_bfgs_b_bounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    242\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# constraints=constraints,\u001b[39;49;00m\n\u001b[32m    243\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallback\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    244\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpass_batch_indices\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    245\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mminimize_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    246\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    247\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results:\n\u001b[32m    248\u001b[39m     _process_scipy_result(res=res, options=options)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/pol_env/lib/python3.11/site-packages/botorch/optim/batched_lbfgs_b.py:358\u001b[39m, in \u001b[36mfmin_l_bfgs_b_batched\u001b[39m\u001b[34m(func, x0, bounds, maxcor, factr, ftol, pgtol, tol, maxiter, disp, callback, maxls, pass_batch_indices)\u001b[39m\n\u001b[32m    347\u001b[39m callback = _wrap_callback(callback)\n\u001b[32m    348\u001b[39m opts = {\n\u001b[32m    349\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmaxcor\u001b[39m\u001b[33m\"\u001b[39m: maxcor,\n\u001b[32m    350\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mftol\u001b[39m\u001b[33m\"\u001b[39m: ftol,\n\u001b[32m   (...)\u001b[39m\u001b[32m    355\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mpass_batch_indices\u001b[39m\u001b[33m\"\u001b[39m: pass_batch_indices,\n\u001b[32m    356\u001b[39m }\n\u001b[32m--> \u001b[39m\u001b[32m358\u001b[39m results = \u001b[43m_minimize_lbfgsb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mopts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    359\u001b[39m fs = [res[\u001b[33m\"\u001b[39m\u001b[33mfun\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results]\n\u001b[32m    360\u001b[39m xs = [res[\u001b[33m\"\u001b[39m\u001b[33mx\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/pol_env/lib/python3.11/site-packages/botorch/optim/batched_lbfgs_b.py:569\u001b[39m, in \u001b[36m_minimize_lbfgsb\u001b[39m\u001b[34m(fun, x0, bounds, maxcor, ftol, gtol, maxiter, callback, maxls, pass_batch_indices, **unknown_options)\u001b[39m\n\u001b[32m    567\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m pass_batch_indices:\n\u001b[32m    568\u001b[39m     batch_indices = [i \u001b[38;5;28;01mfor\u001b[39;00m i, do_fw \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(do_forward) \u001b[38;5;28;01mif\u001b[39;00m do_fw]\n\u001b[32m--> \u001b[39m\u001b[32m569\u001b[39m     total_f, total_g = \u001b[43mfunc_and_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_indices\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_indices\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    570\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    571\u001b[39m     total_f, total_g = func_and_grad(total_x)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/pol_env/lib/python3.11/site-packages/botorch/generation/gen.py:427\u001b[39m, in \u001b[36m_get_f_np_wrapper.<locals>.f_np_wrapper\u001b[39m\u001b[34m(x, f, fixed_features, batch_indices)\u001b[39m\n\u001b[32m    421\u001b[39m X_fix = fix_features(\n\u001b[32m    422\u001b[39m     X, fixed_features=this_fixed_features, replace_current_value=\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    423\u001b[39m )\n\u001b[32m    424\u001b[39m \u001b[38;5;66;03m# we compute the loss on the whole batch, under the assumption that f\u001b[39;00m\n\u001b[32m    425\u001b[39m \u001b[38;5;66;03m# treats multiple inputs in the 0th dimension as independent\u001b[39;00m\n\u001b[32m    426\u001b[39m \u001b[38;5;66;03m# inputs in a batch\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m427\u001b[39m losses = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_fix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    428\u001b[39m loss = losses.sum()\n\u001b[32m    429\u001b[39m \u001b[38;5;66;03m# compute gradient w.r.t. the inputs (does not accumulate in leaves)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/pol_env/lib/python3.11/site-packages/botorch/generation/gen.py:186\u001b[39m, in \u001b[36mgen_candidates_scipy.<locals>.f\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m    185\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mf\u001b[39m(x):\n\u001b[32m--> \u001b[39m\u001b[32m186\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m -\u001b[43macquisition_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/pol_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/pol_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/pol_env/lib/python3.11/site-packages/botorch/utils/transforms.py:396\u001b[39m, in \u001b[36mconcatenate_pending_points.<locals>.decorated\u001b[39m\u001b[34m(cls, X, **kwargs)\u001b[39m\n\u001b[32m    394\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m.X_pending \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    395\u001b[39m     X = torch.cat([X, match_batch_shape(\u001b[38;5;28mcls\u001b[39m.X_pending, X)], dim=-\u001b[32m2\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m396\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/pol_env/lib/python3.11/site-packages/botorch/utils/transforms.py:299\u001b[39m, in \u001b[36mt_batch_mode_transform.<locals>.decorator.<locals>.decorated\u001b[39m\u001b[34m(acqf, X, *args, **kwargs)\u001b[39m\n\u001b[32m    297\u001b[39m \u001b[38;5;66;03m# add t-batch dim\u001b[39;00m\n\u001b[32m    298\u001b[39m X = X \u001b[38;5;28;01mif\u001b[39;00m X.dim() > \u001b[32m2\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m X.unsqueeze(\u001b[32m0\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m299\u001b[39m output = \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[43macqf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    300\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m assert_output_shape \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _verify_output_shape(\n\u001b[32m    301\u001b[39m     acqf=acqf,\n\u001b[32m    302\u001b[39m     X=X,\n\u001b[32m    303\u001b[39m     output=output,\n\u001b[32m    304\u001b[39m ):\n\u001b[32m    305\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[32m    306\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mExpected the output shape to match either the t-batch shape of \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    307\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mX, or the `model.batch_shape` in the case of acquisition \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    316\u001b[39m         )\n\u001b[32m    317\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/pol_env/lib/python3.11/site-packages/botorch/utils/transforms.py:362\u001b[39m, in \u001b[36maverage_over_ensemble_models.<locals>.decorated\u001b[39m\u001b[34m(acqf, X, *args, **kwargs)\u001b[39m\n\u001b[32m    361\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorated\u001b[39m(acqf: AcquisitionFunction, X: Any, *args: Any, **kwargs: Any) -> Any:\n\u001b[32m--> \u001b[39m\u001b[32m362\u001b[39m     output = \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[43macqf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    363\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(acqf, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m is_ensemble(acqf.model):\n\u001b[32m    364\u001b[39m         output = (\n\u001b[32m    365\u001b[39m             output.mean(dim=-\u001b[32m1\u001b[39m)\n\u001b[32m    366\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(acqf, \u001b[33m\"\u001b[39m\u001b[33m_log\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    367\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m logmeanexp(output, dim=-\u001b[32m1\u001b[39m)\n\u001b[32m    368\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/pol_env/lib/python3.11/site-packages/botorch/acquisition/multi_objective/logei.py:467\u001b[39m, in \u001b[36mqLogNoisyExpectedHypervolumeImprovement.forward\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    465\u001b[39m q_in = X.shape[-\u001b[32m2\u001b[39m] * n_w\n\u001b[32m    466\u001b[39m \u001b[38;5;28mself\u001b[39m._set_sampler(q_in=q_in, posterior=posterior)\n\u001b[32m--> \u001b[39m\u001b[32m467\u001b[39m samples = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_f_X_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mposterior\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposterior\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mq_in\u001b[49m\u001b[43m=\u001b[49m\u001b[43mq_in\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    468\u001b[39m \u001b[38;5;66;03m# Add previous nehvi from pending points.\u001b[39;00m\n\u001b[32m    469\u001b[39m nehvi = \u001b[38;5;28mself\u001b[39m._compute_log_qehvi(samples=samples, X=X)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/pol_env/lib/python3.11/site-packages/botorch/acquisition/cached_cholesky.py:141\u001b[39m, in \u001b[36mCachedCholeskyMCSamplerMixin._get_f_X_samples\u001b[39m\u001b[34m(self, posterior, q_in)\u001b[39m\n\u001b[32m    139\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._cache_root \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m_baseline_L\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    140\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m141\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msample_cached_cholesky\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    142\u001b[39m \u001b[43m            \u001b[49m\u001b[43mposterior\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposterior\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    143\u001b[39m \u001b[43m            \u001b[49m\u001b[43mbaseline_L\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_baseline_L\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    144\u001b[39m \u001b[43m            \u001b[49m\u001b[43mq\u001b[49m\u001b[43m=\u001b[49m\u001b[43mq_in\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    145\u001b[39m \u001b[43m            \u001b[49m\u001b[43mbase_samples\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msampler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbase_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    146\u001b[39m \u001b[43m            \u001b[49m\u001b[43msample_shape\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msampler\u001b[49m\u001b[43m.\u001b[49m\u001b[43msample_shape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    147\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    148\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m (NanError, NotPSDError):\n\u001b[32m    149\u001b[39m         warnings.warn(\n\u001b[32m    150\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mLow-rank cholesky updates failed due NaNs or due to an \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    151\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mill-conditioned covariance matrix. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    154\u001b[39m             stacklevel=\u001b[32m3\u001b[39m,\n\u001b[32m    155\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/pol_env/lib/python3.11/site-packages/botorch/utils/low_rank.py:118\u001b[39m, in \u001b[36msample_cached_cholesky\u001b[39m\u001b[34m(posterior, baseline_L, q, base_samples, sample_shape, max_tries)\u001b[39m\n\u001b[32m    112\u001b[39m lazy_covar = (\n\u001b[32m    113\u001b[39m     extract_batch_covar(mt_mvn=mvn)\n\u001b[32m    114\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mvn, MultitaskMultivariateNormal)\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m mvn.lazy_covariance_matrix\n\u001b[32m    116\u001b[39m )\n\u001b[32m    117\u001b[39m \u001b[38;5;66;03m# Get the `q` new rows of the batched covariance matrix\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m118\u001b[39m bottom_rows = \u001b[43mlazy_covar\u001b[49m\u001b[43m[\u001b[49m\u001b[43m.\u001b[49m\u001b[43m.\u001b[49m\u001b[43m.\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43mq\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_dense\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    119\u001b[39m \u001b[38;5;66;03m# The covariance in block form is:\u001b[39;00m\n\u001b[32m    120\u001b[39m \u001b[38;5;66;03m# [K(X_baseline, X_baseline), K(X_baseline, X)]\u001b[39;00m\n\u001b[32m    121\u001b[39m \u001b[38;5;66;03m# [K(X, X_baseline), K(X, X)]\u001b[39;00m\n\u001b[32m    122\u001b[39m \u001b[38;5;66;03m# bl := K(X, X_baseline)\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;66;03m# br := K(X, X)\u001b[39;00m\n\u001b[32m    124\u001b[39m \u001b[38;5;66;03m# Get bottom right block of new covariance\u001b[39;00m\n\u001b[32m    125\u001b[39m bl, br = bottom_rows.split([bottom_rows.shape[-\u001b[32m1\u001b[39m] - q, q], dim=-\u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/pol_env/lib/python3.11/site-packages/linear_operator/operators/cat_linear_operator.py:384\u001b[39m, in \u001b[36mCatLinearOperator.to_dense\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    383\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mto_dense\u001b[39m(\u001b[38;5;28mself\u001b[39m: Float[LinearOperator, \u001b[33m\"\u001b[39m\u001b[33m*batch M N\u001b[39m\u001b[33m\"\u001b[39m]) -> Float[Tensor, \u001b[33m\"\u001b[39m\u001b[33m*batch M N\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m--> \u001b[39m\u001b[32m384\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m torch.cat(\u001b[43m[\u001b[49m\u001b[43mto_dense\u001b[49m\u001b[43m(\u001b[49m\u001b[43mL\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mL\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlinear_ops\u001b[49m\u001b[43m]\u001b[49m, dim=\u001b[38;5;28mself\u001b[39m.cat_dim)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/pol_env/lib/python3.11/site-packages/linear_operator/operators/cat_linear_operator.py:384\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m    383\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mto_dense\u001b[39m(\u001b[38;5;28mself\u001b[39m: Float[LinearOperator, \u001b[33m\"\u001b[39m\u001b[33m*batch M N\u001b[39m\u001b[33m\"\u001b[39m]) -> Float[Tensor, \u001b[33m\"\u001b[39m\u001b[33m*batch M N\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m--> \u001b[39m\u001b[32m384\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m torch.cat([\u001b[43mto_dense\u001b[49m\u001b[43m(\u001b[49m\u001b[43mL\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m L \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.linear_ops], dim=\u001b[38;5;28mself\u001b[39m.cat_dim)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/pol_env/lib/python3.11/site-packages/linear_operator/operators/_linear_operator.py:2993\u001b[39m, in \u001b[36mto_dense\u001b[39m\u001b[34m(obj)\u001b[39m\n\u001b[32m   2991\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\n\u001b[32m   2992\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, LinearOperator):\n\u001b[32m-> \u001b[39m\u001b[32m2993\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_dense\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2994\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2995\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mobject of class \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m cannot be made into a Tensor\u001b[39m\u001b[33m\"\u001b[39m.format(obj.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/pol_env/lib/python3.11/site-packages/linear_operator/utils/memoize.py:59\u001b[39m, in \u001b[36m_cached.<locals>.g\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     57\u001b[39m kwargs_pkl = pickle.dumps(kwargs)\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_in_cache(\u001b[38;5;28mself\u001b[39m, cache_name, *args, kwargs_pkl=kwargs_pkl):\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _add_to_cache(\u001b[38;5;28mself\u001b[39m, cache_name, \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m, *args, kwargs_pkl=kwargs_pkl)\n\u001b[32m     60\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _get_from_cache(\u001b[38;5;28mself\u001b[39m, cache_name, *args, kwargs_pkl=kwargs_pkl)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/pol_env/lib/python3.11/site-packages/linear_operator/operators/matmul_linear_operator.py:133\u001b[39m, in \u001b[36mMatmulLinearOperator.to_dense\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    131\u001b[39m \u001b[38;5;129m@cached\u001b[39m\n\u001b[32m    132\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mto_dense\u001b[39m(\u001b[38;5;28mself\u001b[39m: Float[LinearOperator, \u001b[33m\"\u001b[39m\u001b[33m*batch M N\u001b[39m\u001b[33m\"\u001b[39m]) -> Float[Tensor, \u001b[33m\"\u001b[39m\u001b[33m*batch M N\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m--> \u001b[39m\u001b[32m133\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mleft_linear_op\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_dense\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mright_linear_op\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_dense\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") \n",
    "# Mine 2,000 sequences of length 20 with iid-uniform sampling\n",
    "dataset = mine_sequences_dataset(\n",
    "    n_iter=20,\n",
    "    n_samples=10000,\n",
    "    n_init=3,\n",
    "    sigma=0.05,\n",
    "    seed=777,\n",
    "    sampler=\"iid_uniform\",              # or \"dirichlet_per_sequence\" / \"phase_bias\"\n",
    "    save_path=\"mined_sequences.pt\",     # autosaves every 10 runs\n",
    "    save_every=1,\n",
    "    log_every=50,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "55ba8398",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def hv_auc(hv_curve: Sequence[float]) -> float:\n",
    "    \"\"\"Compute AUC of a Hypervolume (HV) trajectory using the trapezoidal rule.\n",
    "\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    hv_curve : Sequence[float]\n",
    "    HV values over time, including HV after initialization at index 0.\n",
    "\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "    Area under the HV-vs-iteration curve (dx=1). Higher is better.\n",
    "    \"\"\"\n",
    "    hv = np.asarray(hv_curve, dtype=float).reshape(-1)\n",
    "    # Trapezoidal rule with uniform spacing of 1 iteration between points.\n",
    "    return float(np.trapz(hv, dx=1.0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e3eff14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded = torch.load(\"mined_sequences.pt\", map_location=\"cuda\", weights_only=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "bd1ec5bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'seed': 777,\n",
       " 'seq': ['m52_ard',\n",
       "  'm52_indep2',\n",
       "  'm32_ard_indep2',\n",
       "  'm32_ard_indep2',\n",
       "  'm52_ard_indep2',\n",
       "  'm52_indep2',\n",
       "  'rbf_iso',\n",
       "  'm52_ard',\n",
       "  'm32_ard_indep2',\n",
       "  'm52_ard_indep2',\n",
       "  'm32_ard_indep2',\n",
       "  'm32_ard_indep2',\n",
       "  'm32_ard_indep2',\n",
       "  'rbf_iso',\n",
       "  'rbf_iso',\n",
       "  'rbf_iso',\n",
       "  'rbf_iso',\n",
       "  'm52_indep2',\n",
       "  'm52_ard_indep2',\n",
       "  'rbf_iso'],\n",
       " 'models': ['m52_ard_indep2',\n",
       "  'm32_ard_indep2',\n",
       "  'rbf_iso',\n",
       "  'm52_indep2',\n",
       "  'm52_ard'],\n",
       " 'n_init': 3,\n",
       " 'sigma': 0.05,\n",
       " 'use_qnehvi': True,\n",
       " 'X_full': array([[0.9874606 , 0.54505543, 0.44787733, 0.65013369],\n",
       "        [0.8709931 , 0.47669355, 0.95417073, 0.38860444],\n",
       "        [0.67062469, 0.54273628, 0.58713837, 0.81612034],\n",
       "        [0.97056265, 1.        , 0.        , 1.        ],\n",
       "        [0.44803746, 1.        , 0.        , 1.        ],\n",
       "        [0.        , 1.        , 1.        , 1.        ],\n",
       "        [0.        , 0.7130626 , 0.        , 0.20792728],\n",
       "        [1.        , 1.        , 1.        , 0.98473269],\n",
       "        [0.54539339, 1.        , 1.        , 1.        ],\n",
       "        [1.        , 1.        , 0.        , 1.        ],\n",
       "        [0.49576615, 0.9923179 , 0.00165637, 0.69936223],\n",
       "        [0.9359703 , 0.99654198, 0.        , 0.97279584],\n",
       "        [0.94716398, 0.99884476, 0.84981514, 0.56790648],\n",
       "        [0.95428315, 0.99091793, 0.00430245, 0.80022858],\n",
       "        [1.        , 0.92184089, 0.99515299, 0.15906386],\n",
       "        [0.95451434, 0.        , 0.        , 0.51775877],\n",
       "        [1.        , 0.        , 1.        , 1.        ],\n",
       "        [1.        , 0.05444341, 1.        , 1.        ],\n",
       "        [0.94871702, 0.03614079, 1.        , 1.        ],\n",
       "        [1.        , 0.03634035, 0.94990201, 1.        ],\n",
       "        [0.31864368, 0.        , 1.        , 1.        ],\n",
       "        [0.99999954, 0.10560155, 1.        , 0.22701987],\n",
       "        [0.2241723 , 1.        , 1.        , 1.        ]]),\n",
       " 'Y_full': array([[0.70726602, 0.48886469],\n",
       "        [0.51311572, 0.44836989],\n",
       "        [0.59176809, 0.51322183],\n",
       "        [1.        , 0.61282068],\n",
       "        [0.65461453, 0.70031248],\n",
       "        [0.16690569, 1.        ],\n",
       "        [0.47679102, 0.1280076 ],\n",
       "        [0.80047718, 1.        ],\n",
       "        [0.55570263, 1.        ],\n",
       "        [0.88561188, 0.61513403],\n",
       "        [0.57833515, 0.38999707],\n",
       "        [0.99710655, 0.62953619],\n",
       "        [0.4571617 , 0.49021375],\n",
       "        [0.77453847, 0.3920227 ],\n",
       "        [0.53894733, 0.3723236 ],\n",
       "        [0.81673303, 0.32693283],\n",
       "        [0.94462842, 0.90881142],\n",
       "        [0.97004122, 0.85733337],\n",
       "        [0.84995886, 0.90276963],\n",
       "        [0.9281927 , 0.84403656],\n",
       "        [0.58478255, 0.78882214],\n",
       "        [0.61234693, 0.30112177],\n",
       "        [0.28701031, 1.        ]]),\n",
       " 'HV': array([0.36017116, 0.61282068, 0.67009408, 0.72011364, 0.72011364,\n",
       "        0.92274889, 0.92274889, 0.92294584, 0.92294584, 0.92603565,\n",
       "        0.92603565, 0.92603565, 0.92603565, 0.92603565, 0.96629352,\n",
       "        0.97208248, 0.97208248, 0.97208248, 0.97208248, 0.97208248,\n",
       "        0.97208248]),\n",
       " 'X_iter': [array([[0.97056265, 1.        , 0.        , 1.        ]]),\n",
       "  array([[0.44803746, 1.        , 0.        , 1.        ]]),\n",
       "  array([[0., 1., 1., 1.]]),\n",
       "  array([[0.        , 0.7130626 , 0.        , 0.20792728]]),\n",
       "  array([[1.        , 1.        , 1.        , 0.98473269]]),\n",
       "  array([[0.54539339, 1.        , 1.        , 1.        ]]),\n",
       "  array([[1., 1., 0., 1.]]),\n",
       "  array([[0.49576615, 0.9923179 , 0.00165637, 0.69936223]]),\n",
       "  array([[0.9359703 , 0.99654198, 0.        , 0.97279584]]),\n",
       "  array([[0.94716398, 0.99884476, 0.84981514, 0.56790648]]),\n",
       "  array([[0.95428315, 0.99091793, 0.00430245, 0.80022858]]),\n",
       "  array([[1.        , 0.92184089, 0.99515299, 0.15906386]]),\n",
       "  array([[0.95451434, 0.        , 0.        , 0.51775877]]),\n",
       "  array([[1., 0., 1., 1.]]),\n",
       "  array([[1.        , 0.05444341, 1.        , 1.        ]]),\n",
       "  array([[0.94871702, 0.03614079, 1.        , 1.        ]]),\n",
       "  array([[1.        , 0.03634035, 0.94990201, 1.        ]]),\n",
       "  array([[0.31864368, 0.        , 1.        , 1.        ]]),\n",
       "  array([[0.99999954, 0.10560155, 1.        , 0.22701987]]),\n",
       "  array([[0.2241723, 1.       , 1.       , 1.       ]])],\n",
       " 'Y_iter': [array([[1.        , 0.61282068]]),\n",
       "  array([[0.65461453, 0.70031248]]),\n",
       "  array([[0.16690569, 1.        ]]),\n",
       "  array([[0.47679102, 0.1280076 ]]),\n",
       "  array([[0.80047718, 1.        ]]),\n",
       "  array([[0.55570263, 1.        ]]),\n",
       "  array([[0.88561188, 0.61513403]]),\n",
       "  array([[0.57833515, 0.38999707]]),\n",
       "  array([[0.99710655, 0.62953619]]),\n",
       "  array([[0.4571617 , 0.49021375]]),\n",
       "  array([[0.77453847, 0.3920227 ]]),\n",
       "  array([[0.53894733, 0.3723236 ]]),\n",
       "  array([[0.81673303, 0.32693283]]),\n",
       "  array([[0.94462842, 0.90881142]]),\n",
       "  array([[0.97004122, 0.85733337]]),\n",
       "  array([[0.84995886, 0.90276963]]),\n",
       "  array([[0.9281927 , 0.84403656]]),\n",
       "  array([[0.58478255, 0.78882214]]),\n",
       "  array([[0.61234693, 0.30112177]]),\n",
       "  array([[0.28701031, 1.        ]])]}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f32e4999",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_auc_idx = np.argmax([hv_auc(loaded[i][\"HV\"]) for i in range(len(loaded))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "df3112b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(4587)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_auc_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6ce94774",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'seed': 5364,\n",
       " 'seq': ['rbf_iso',\n",
       "  'm52_indep2',\n",
       "  'm52_ard',\n",
       "  'm52_indep2',\n",
       "  'rbf_iso',\n",
       "  'm32_ard_indep2',\n",
       "  'm52_ard',\n",
       "  'm52_indep2',\n",
       "  'rbf_iso',\n",
       "  'm52_ard',\n",
       "  'm52_ard_indep2',\n",
       "  'm52_ard',\n",
       "  'm52_ard_indep2',\n",
       "  'rbf_iso',\n",
       "  'm52_indep2',\n",
       "  'm52_indep2',\n",
       "  'm52_ard_indep2',\n",
       "  'm32_ard_indep2',\n",
       "  'm32_ard_indep2',\n",
       "  'm52_ard'],\n",
       " 'models': ['m52_ard_indep2',\n",
       "  'm32_ard_indep2',\n",
       "  'rbf_iso',\n",
       "  'm52_indep2',\n",
       "  'm52_ard'],\n",
       " 'n_init': 3,\n",
       " 'sigma': 0.05,\n",
       " 'use_qnehvi': True,\n",
       " 'X_full': array([[0.94245181, 0.02865878, 0.96919409, 0.71254604],\n",
       "        [0.8539166 , 0.20890767, 0.48399645, 0.12403026],\n",
       "        [0.53321766, 0.6519589 , 0.8103105 , 0.40842953],\n",
       "        [1.        , 0.        , 1.        , 0.85593109],\n",
       "        [1.        , 0.        , 1.        , 1.        ],\n",
       "        [0.        , 0.        , 0.        , 1.        ],\n",
       "        [0.78373633, 0.        , 1.        , 1.        ],\n",
       "        [1.        , 0.23058357, 1.        , 1.        ],\n",
       "        [1.        , 1.        , 0.77739591, 1.        ],\n",
       "        [1.        , 0.4064401 , 0.        , 1.        ],\n",
       "        [1.        , 0.07019508, 0.72170454, 1.        ],\n",
       "        [0.        , 1.        , 1.        , 1.        ],\n",
       "        [0.38688051, 0.77456377, 0.91360525, 0.08722334],\n",
       "        [0.70520624, 0.        , 0.        , 1.        ],\n",
       "        [0.99999765, 0.30318545, 1.        , 1.        ],\n",
       "        [1.        , 0.        , 0.        , 1.        ],\n",
       "        [1.        , 1.        , 1.        , 1.        ],\n",
       "        [1.        , 0.10068431, 0.98761253, 1.        ],\n",
       "        [0.94263408, 0.        , 0.8892558 , 1.        ],\n",
       "        [1.        , 0.35277092, 0.31700229, 1.        ],\n",
       "        [0.14098673, 0.51510455, 0.80580709, 0.44440236],\n",
       "        [0.01654552, 0.        , 1.        , 1.        ],\n",
       "        [0.99999943, 0.71942838, 1.        , 1.        ]]),\n",
       " 'Y_full': array([[0.73024205, 0.60188335],\n",
       "        [0.45210472, 0.09226987],\n",
       "        [0.45438476, 0.41369751],\n",
       "        [0.86027771, 0.77079108],\n",
       "        [1.        , 1.        ],\n",
       "        [0.86111326, 0.45245493],\n",
       "        [0.84563323, 0.8787506 ],\n",
       "        [1.        , 0.93270599],\n",
       "        [0.8020676 , 0.87105072],\n",
       "        [0.9888392 , 0.62122942],\n",
       "        [0.9410913 , 0.88106342],\n",
       "        [0.13714944, 1.        ],\n",
       "        [0.26275468, 0.07722646],\n",
       "        [0.96186665, 0.55915151],\n",
       "        [0.97545329, 0.78619132],\n",
       "        [0.95445271, 0.64360278],\n",
       "        [0.79146171, 1.        ],\n",
       "        [0.94958338, 0.86229082],\n",
       "        [0.9027078 , 0.74072682],\n",
       "        [0.84839129, 0.55509559],\n",
       "        [0.2043668 , 0.42113873],\n",
       "        [0.46050075, 0.80278315],\n",
       "        [0.8495892 , 1.        ]]),\n",
       " 'HV': array([0.43952053, 0.66309439, 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        ]),\n",
       " 'X_iter': [array([[1.        , 0.        , 1.        , 0.85593109]]),\n",
       "  array([[1., 0., 1., 1.]]),\n",
       "  array([[0., 0., 0., 1.]]),\n",
       "  array([[0.78373633, 0.        , 1.        , 1.        ]]),\n",
       "  array([[1.        , 0.23058357, 1.        , 1.        ]]),\n",
       "  array([[1.        , 1.        , 0.77739591, 1.        ]]),\n",
       "  array([[1.       , 0.4064401, 0.       , 1.       ]]),\n",
       "  array([[1.        , 0.07019508, 0.72170454, 1.        ]]),\n",
       "  array([[0., 1., 1., 1.]]),\n",
       "  array([[0.38688051, 0.77456377, 0.91360525, 0.08722334]]),\n",
       "  array([[0.70520624, 0.        , 0.        , 1.        ]]),\n",
       "  array([[0.99999765, 0.30318545, 1.        , 1.        ]]),\n",
       "  array([[1., 0., 0., 1.]]),\n",
       "  array([[1., 1., 1., 1.]]),\n",
       "  array([[1.        , 0.10068431, 0.98761253, 1.        ]]),\n",
       "  array([[0.94263408, 0.        , 0.8892558 , 1.        ]]),\n",
       "  array([[1.        , 0.35277092, 0.31700229, 1.        ]]),\n",
       "  array([[0.14098673, 0.51510455, 0.80580709, 0.44440236]]),\n",
       "  array([[0.01654552, 0.        , 1.        , 1.        ]]),\n",
       "  array([[0.99999943, 0.71942838, 1.        , 1.        ]])],\n",
       " 'Y_iter': [array([[0.86027771, 0.77079108]]),\n",
       "  array([[1., 1.]]),\n",
       "  array([[0.86111326, 0.45245493]]),\n",
       "  array([[0.84563323, 0.8787506 ]]),\n",
       "  array([[1.        , 0.93270599]]),\n",
       "  array([[0.8020676 , 0.87105072]]),\n",
       "  array([[0.9888392 , 0.62122942]]),\n",
       "  array([[0.9410913 , 0.88106342]]),\n",
       "  array([[0.13714944, 1.        ]]),\n",
       "  array([[0.26275468, 0.07722646]]),\n",
       "  array([[0.96186665, 0.55915151]]),\n",
       "  array([[0.97545329, 0.78619132]]),\n",
       "  array([[0.95445271, 0.64360278]]),\n",
       "  array([[0.79146171, 1.        ]]),\n",
       "  array([[0.94958338, 0.86229082]]),\n",
       "  array([[0.9027078 , 0.74072682]]),\n",
       "  array([[0.84839129, 0.55509559]]),\n",
       "  array([[0.2043668 , 0.42113873]]),\n",
       "  array([[0.46050075, 0.80278315]]),\n",
       "  array([[0.8495892, 1.       ]])]}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded[4587]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "47bbb6be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.938765457238588"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hvs = run_bo( n_init=3, seed= 4587+777,  preset = \"m52_ard\")\n",
    "hv_auc(hvs[2].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "71adfeae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.9425, 0.0287, 0.9692, 0.7125],\n",
       "         [0.8539, 0.2089, 0.4840, 0.1240],\n",
       "         [0.5332, 0.6520, 0.8103, 0.4084],\n",
       "         [0.6353, 0.0000, 1.0000, 0.7822],\n",
       "         [0.0000, 0.0783, 0.9686, 1.0000],\n",
       "         [0.0000, 1.0000, 0.0000, 1.0000],\n",
       "         [0.0000, 0.0896, 1.0000, 0.7218],\n",
       "         [0.7557, 1.0000, 1.0000, 1.0000],\n",
       "         [1.0000, 1.0000, 1.0000, 1.0000],\n",
       "         [0.9174, 0.8571, 1.0000, 1.0000],\n",
       "         [0.5461, 0.7293, 1.0000, 1.0000],\n",
       "         [1.0000, 1.0000, 1.0000, 0.9059],\n",
       "         [0.7643, 1.0000, 1.0000, 0.9482],\n",
       "         [1.0000, 1.0000, 1.0000, 0.9752],\n",
       "         [1.0000, 1.0000, 1.0000, 0.7827],\n",
       "         [0.0000, 1.0000, 1.0000, 1.0000],\n",
       "         [1.0000, 0.0969, 1.0000, 1.0000],\n",
       "         [1.0000, 0.0000, 0.4979, 1.0000],\n",
       "         [1.0000, 0.0000, 0.0000, 1.0000],\n",
       "         [1.0000, 0.7614, 0.0000, 1.0000],\n",
       "         [1.0000, 0.3748, 0.7155, 1.0000],\n",
       "         [0.7570, 0.0000, 0.0000, 1.0000],\n",
       "         [1.0000, 0.0000, 0.2655, 1.0000]]),\n",
       " tensor([[0.7302, 0.6019],\n",
       "         [0.4521, 0.0923],\n",
       "         [0.4544, 0.4137],\n",
       "         [0.6814, 0.6864],\n",
       "         [0.5662, 0.9307],\n",
       "         [0.5700, 0.6010],\n",
       "         [0.3426, 0.6362],\n",
       "         [0.7875, 1.0000],\n",
       "         [0.8003, 0.9965],\n",
       "         [0.7833, 1.0000],\n",
       "         [0.6230, 1.0000],\n",
       "         [0.6765, 0.9022],\n",
       "         [0.6306, 1.0000],\n",
       "         [0.7900, 0.9544],\n",
       "         [0.7323, 0.8110],\n",
       "         [0.2164, 1.0000],\n",
       "         [0.8453, 0.8896],\n",
       "         [0.9851, 0.8017],\n",
       "         [1.0000, 0.7057],\n",
       "         [1.0000, 0.6256],\n",
       "         [0.9163, 0.7947],\n",
       "         [1.0000, 0.5646],\n",
       "         [0.9410, 0.6268]]),\n",
       " tensor([0.4395, 0.4971, 0.6354, 0.6354, 0.6354, 0.7875, 0.8003, 0.8003, 0.8003,\n",
       "         0.8003, 0.8003, 0.8003, 0.8003, 0.8003, 0.8403, 0.9524, 0.9629, 0.9629,\n",
       "         0.9629, 0.9629, 0.9629]))"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ac0f543c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.19292331790844"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hv_auc(hvs[2].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7fce1614",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'seed': 1675,\n",
       " 'seq': ['m52_ard_indep2',\n",
       "  'rbf_iso',\n",
       "  'rbf_iso',\n",
       "  'rbf_iso',\n",
       "  'rbf_iso',\n",
       "  'rbf_iso',\n",
       "  'm52_indep2',\n",
       "  'm52_ard_indep2',\n",
       "  'm32_ard_indep2',\n",
       "  'm52_indep2',\n",
       "  'm52_indep2',\n",
       "  'm32_ard_indep2',\n",
       "  'm52_ard',\n",
       "  'rbf_iso',\n",
       "  'm32_ard_indep2',\n",
       "  'm52_indep2',\n",
       "  'm52_indep2',\n",
       "  'm52_indep2',\n",
       "  'm32_ard_indep2',\n",
       "  'm32_ard_indep2'],\n",
       " 'models': ['m52_ard_indep2',\n",
       "  'm32_ard_indep2',\n",
       "  'rbf_iso',\n",
       "  'm52_indep2',\n",
       "  'm52_ard'],\n",
       " 'n_init': 3,\n",
       " 'sigma': 0.05,\n",
       " 'use_qnehvi': True,\n",
       " 'X_full': array([[0.45889695, 0.20856828, 0.17836936, 0.77905196],\n",
       "        [0.35550151, 0.62742182, 0.18051892, 0.68853323],\n",
       "        [0.37438538, 0.07152966, 0.12487253, 0.58312684],\n",
       "        [0.54371244, 0.29182352, 1.        , 0.27302529],\n",
       "        [0.51370976, 0.04085197, 0.1233356 , 0.89438248],\n",
       "        [0.73746299, 0.14821999, 0.12825845, 0.80732302],\n",
       "        [0.87598901, 0.15420022, 0.31815055, 0.91809302],\n",
       "        [0.9796048 , 0.29497004, 0.14925992, 1.        ],\n",
       "        [1.        , 0.47591897, 0.        , 1.        ],\n",
       "        [1.        , 0.606036  , 0.27869519, 1.        ],\n",
       "        [0.61265458, 0.14766482, 0.73546802, 0.03787331],\n",
       "        [1.        , 0.25143512, 0.91439271, 1.        ],\n",
       "        [0.        , 0.        , 1.        , 1.        ],\n",
       "        [1.        , 1.        , 1.        , 1.        ],\n",
       "        [1.        , 0.33752163, 0.        , 1.        ],\n",
       "        [1.        , 0.        , 0.        , 1.        ],\n",
       "        [1.        , 0.12972413, 0.09244841, 1.        ],\n",
       "        [0.9378243 , 1.        , 0.0566453 , 1.        ],\n",
       "        [0.        , 1.        , 1.        , 1.        ],\n",
       "        [1.        , 0.61805815, 1.        , 1.        ],\n",
       "        [1.        , 0.        , 1.        , 1.        ],\n",
       "        [0.93738235, 0.8060858 , 1.        , 1.        ],\n",
       "        [0.80515551, 1.        , 0.82454288, 1.        ]]),\n",
       " 'Y_full': array([[0.75734479, 0.39897102],\n",
       "        [0.58472713, 0.39967011],\n",
       "        [0.70837058, 0.31722142],\n",
       "        [0.42384552, 0.39346479],\n",
       "        [0.76858568, 0.48649893],\n",
       "        [0.82419201, 0.40732141],\n",
       "        [0.83644628, 0.57474899],\n",
       "        [1.        , 0.62166326],\n",
       "        [1.        , 0.65072742],\n",
       "        [0.83124909, 0.6849778 ],\n",
       "        [0.58743676, 0.03020533],\n",
       "        [0.86165922, 0.84098493],\n",
       "        [0.38271864, 0.85794462],\n",
       "        [0.8559937 , 1.        ],\n",
       "        [1.        , 0.54161682],\n",
       "        [1.        , 0.55922161],\n",
       "        [1.        , 0.50782033],\n",
       "        [0.81119403, 0.61266021],\n",
       "        [0.177702  , 0.99647654],\n",
       "        [0.79513705, 0.99634902],\n",
       "        [1.        , 1.        ],\n",
       "        [0.75438295, 0.93718502],\n",
       "        [0.67875595, 0.90223885]]),\n",
       " 'HV': array([0.3025674 , 0.3025674 , 0.37391611, 0.39656576, 0.48074665,\n",
       "        0.62166326, 0.65072742, 0.67919801, 0.67919801, 0.81466456,\n",
       "        0.82115535, 0.95078046, 0.95078046, 0.95078046, 0.95078046,\n",
       "        0.95078046, 0.95078046, 0.95078046, 1.        , 1.        ,\n",
       "        1.        ]),\n",
       " 'X_iter': [array([[0.54371244, 0.29182352, 1.        , 0.27302529]]),\n",
       "  array([[0.51370976, 0.04085197, 0.1233356 , 0.89438248]]),\n",
       "  array([[0.73746299, 0.14821999, 0.12825845, 0.80732302]]),\n",
       "  array([[0.87598901, 0.15420022, 0.31815055, 0.91809302]]),\n",
       "  array([[0.9796048 , 0.29497004, 0.14925992, 1.        ]]),\n",
       "  array([[1.        , 0.47591897, 0.        , 1.        ]]),\n",
       "  array([[1.        , 0.606036  , 0.27869519, 1.        ]]),\n",
       "  array([[0.61265458, 0.14766482, 0.73546802, 0.03787331]]),\n",
       "  array([[1.        , 0.25143512, 0.91439271, 1.        ]]),\n",
       "  array([[0., 0., 1., 1.]]),\n",
       "  array([[1., 1., 1., 1.]]),\n",
       "  array([[1.        , 0.33752163, 0.        , 1.        ]]),\n",
       "  array([[1., 0., 0., 1.]]),\n",
       "  array([[1.        , 0.12972413, 0.09244841, 1.        ]]),\n",
       "  array([[0.9378243, 1.       , 0.0566453, 1.       ]]),\n",
       "  array([[0., 1., 1., 1.]]),\n",
       "  array([[1.        , 0.61805815, 1.        , 1.        ]]),\n",
       "  array([[1., 0., 1., 1.]]),\n",
       "  array([[0.93738235, 0.8060858 , 1.        , 1.        ]]),\n",
       "  array([[0.80515551, 1.        , 0.82454288, 1.        ]])],\n",
       " 'Y_iter': [array([[0.42384552, 0.39346479]]),\n",
       "  array([[0.76858568, 0.48649893]]),\n",
       "  array([[0.82419201, 0.40732141]]),\n",
       "  array([[0.83644628, 0.57474899]]),\n",
       "  array([[1.        , 0.62166326]]),\n",
       "  array([[1.        , 0.65072742]]),\n",
       "  array([[0.83124909, 0.6849778 ]]),\n",
       "  array([[0.58743676, 0.03020533]]),\n",
       "  array([[0.86165922, 0.84098493]]),\n",
       "  array([[0.38271864, 0.85794462]]),\n",
       "  array([[0.8559937, 1.       ]]),\n",
       "  array([[1.        , 0.54161682]]),\n",
       "  array([[1.        , 0.55922161]]),\n",
       "  array([[1.        , 0.50782033]]),\n",
       "  array([[0.81119403, 0.61266021]]),\n",
       "  array([[0.177702  , 0.99647654]]),\n",
       "  array([[0.79513705, 0.99634902]]),\n",
       "  array([[1., 1.]]),\n",
       "  array([[0.75438295, 0.93718502]]),\n",
       "  array([[0.67875595, 0.90223885]])]}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded[898]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pol_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
